<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>UM EECS 398-002/598-010 - Introduction to Autonomous Robotics</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">

    <!-- Combo with CSSNormalize, CSSGrids-Responsive, CSSForm, CSSTable, CSSList (v3.9.1) -->
    <link rel="stylesheet" href="resources/yahoo_cssbutton-min.css">
    <link rel="stylesheet" href="resources/yahoo_gallerycss-cssform-min.css">
    <link rel="stylesheet" href="resources/yahoo_cssgrids-responsive-min.css">
    <link rel="stylesheet" href="resources/yahoo_gallerycss-csslist-min.css">
    <link rel="stylesheet" href="resources/yahoo_cssnormalize-min.css">
    <link rel="stylesheet" href="resources/yahoo_gallerycss-csstable-min.css">

    <!-- Some custom styles to make things pretty. -->
    <link rel="stylesheet" type="text/css" href="resources/ui.css">

    <!-- RainbowJS Syntax Highlighting - Github Theme. 
         For more themes, go to https://github.com/ccampbell/rainbow/tree/master/themes -->
    <link rel="stylesheet" type="text/css" href="resources/rainbow_github.css">


    <!-- Modify header colors here to customize the look and feel of the site-->
    <style>
        
        .header {
            background: rgb(0, 39, 76);
         }
            .header h1 {
                color: white;
            }
             .header h2 {
                 font-weight:300;
                 margin:0;
                 color: rgb(116, 130, 230);
             }
    </style>

</head>

<body class='yui3-skin-sam'>

    <div id="headerMenu" class="yui3-menu yui3-menu-open yui3-menu-horizontal yui3-menu-fixed">
        <span class="yui3-menu-heading">AutoRob</span>
        <ul>
            <li class="yui3-menu-active"><a href="#schedule">schedule</a></li>
            <li><a href="https://github.com/ohseejay/kineval-stencil">kineval</a></li>
            <li><a href="#git_tutorial">git</a></li>
            assignments:
            <li><a href="#assignment1">1</a></li>
            <li><a href="#assignment2">2</a></li>
            <li><a href="#assignment3">3</a></li>
            <li><a href="#assignment4">4</a></li>
<!-- unassigned
            <li><a href="#assignment5">5</a></li>
            <li><a href="#assignment6">6</a></li>
            <li><a href="#assignment7">7</a></li>
-->
        </ul>
    </div>
    <div class="header yui3-u-1">

        <h1 class="yui3-u-1">UM EECS 398-002</h1>
        <h2 class="yui3-u">Introduction to Autonomous Robotics</h2>
        <h1 class="yui3-u-1">UM EECS 598-010</h1>
        <h2 class="yui3-u">Robot Modeling and Control</h2>
        <br>
        <br>
        <h2 class="yui3-u">Winter 2016</h2>

     </div>
    <div class="content">
<p>
<center>
<img width=100% src="images/um_fetch.jpg">
</center>


<!--
<h2> Under Construction </h2> 
<p>
The AutoRob course site is still in preparation for Winter 2016.  Following a similar structure, AutoRob will be an improved version of <a href="http://browncs148.github.io/">CS 148</a> previously taught at Brown University for both graduate and undergraduate students.  AutoRob will be taught in two sections: EECS 398-002 (Introduction to Autonomous Robotics) for upper-level undergraduate credit, and EECS 598-010 (Robot Modeling and Control) for graduate credit.  Both sections will offered at the same meeting time and location (MW 1:30-3, Dow 2166).  While the course is being updated, some preliminary materials and syllabus are available below, as well as a quick demonstration video...
</p>

<center>
<iframe width="420" height="315" src="https://www.youtube.com/embed/ag0j8HzFRzc" frameborder="0" allowfullscreen></iframe>
</center>

<p>
and recent pics from our Fetch robot grabbing some lunch (courtesy Michael DeVries @MikeTDeVries).  Yes, that was this robot that was at Pierpoint Commons:
</p>


<a href="https://twitter.com/MikeTDeVries/status/671391942631153665">
<img width=100% src="images/umdining_fetch.png">
</a>
-->
 


        <h2>Introduction</h2>

<p>
Introduction to Autonomous Robotics (AutoRob) is an introduction to core topics in the modeling and control of autonomous robots. The AutoRob course can be thought of as the foundation to build “brains for robots”. That is, given a robot as a machine with sensing, actuation, and computation, how do we develop programs that allow the robot to function autonomously? Such programs involve functions for robots to perceive the world, make decisions towards achieving a given objective, and transforming decided actions into motor commands.  These functions are essential for modern robotics, especially for mobile manipulators such as the pictured <a href="http://fetchrobotics.com/research/">Fetch</a> and <a href="https://www.willowgarage.com/pages/pr2/overview">PR2</a> robots.
</p>

<p>
The AutoRob course focuses on the issues of modeling and control for autonomous robots with an emphasis on manipulation and mobility.  Successful completion of AutoRob will result in code modules for "mobile pick-and-place".  That is, given a robot and perception of the robot's environment, resulting code modules can enable the robot to pick up an object at an arbitrary location and place the object in a new location.
</p>

<!--
Caveats: robot will perform suboptimally based on rrt-planner, no self-collision checking, assume object is graspable and pickable, need grasp planner, no respect for joint motor and angle limits, translate between ROS
-->


<p>
AutoRob projects ground course concepts through implementation in JavaScript/HTML5 supported by the KinEval code stencil (snapshot below from Mozilla Firefox).  These projects will cover basic physical simulation (Lagrangian dynamics, numerical integrators), proportional-integral-derivative control, forward kinematics (3D geometric matrix transforms, matrix stack composition of transforms, axis-angle rotation by quaternions), inverse kinematics, (gradient descent optimization, Jacobians for velocity kinematics), and motion planning (simple collision detection, sample-based motion planning).  Optional non-project topics will be covered for A* planning, potential field navigation, Bayesian filtering, Monte Carlo localization, and Newton-Euler dynamics.  
</p>

<img width=100% src="images/kineval_fetch.png">

<p>
AutoRob projects will roughly follow conventions and structures from the <a href="http://ros.org">Robot Operating System (ROS)<a> and <a href="https://github.com/RobotWebTools">Robot Web Tools (RWT)</a> software frameworks, as currently used on the Fetch and PR2 robots.  These conventions include the URDF kinematic modeling format, ROS topic structure, JSON-based messaging.

Kineval uses <a href="http://threejs.org/">threejs</a> for in-browser 3D rendering and <a href="http://numericjs.com">Numeric Javascript</a> for select matrix routines.  Auxiliary code examples and stencils will often use the <a href="http://jsfiddle.net/">jsfiddle</a> development environment.    
</p>

<h3>Related Courses</h3>

<p>
AutoRob is a computing-friendly pathway into robotics, but does not cover the whole of robotics.  The scope of AutoRob is robot modeling and control, which is well-suited as preparation for a Major Design Experience in EECS 467 (Autonomous Robotics Laboratory).  ME 567 (Robot Kinematics and Dynamics) and AutoRob share coverage of many similar topics, with ME 567 providing more in-depth mathematical analysis and usage of Denavit-Hartenberg parameters.  
</p>

<p>
AutoRob is also a complement to courses covering perception (EECS 568 Mobile Robotics, EECS 442 Computer Vision), robot building (EECS 498 Hands-on Robotics, ME 552 Mechatronics), robot simulation (ME 543 Analytical and Computational Dynamics), controls systems (EECS 460 Control Systems Analysis and Design, EECS 461 Embedded Control Systems), and artificial intelligence (EECS 492 Introduction to Artificial Intelligence), as well as general graduate courses in robotics (ROB 501 Math for Robotics, ROB 550 Robotic Systems Laboratory).  
</p>

<p>

<h2>Course Staff</h2>

<h3>Instructor</h3>

<p><a href="http://web.eecs.umich.edu/~ocj">Chad Jenkins</a> 
<br>
ocj addrsign umich
<br>
Office: Beyster 3644
<br>
Office Hours: Monday 3:30-5pm, Thursday 1-3pm
</p>

<h3>GSI</h3>

<p>Irina Klissourova
<br>
irinakl addrsign umich
<br>
Office: Beyster 3912
<br>
Office Hours: Tuesday 1:30-3pm, Thursday 1:30-3pm
</p>



<h2>Meeting time/place</h2>
<p>
Monday, Wednesday 1:30-3:00 
<br>DOW 2150
<br><del>DOW 2166</del>
</p>

<h2>Discussion channel</h2>

<p>
<a href="https://autorob.slack.com/messages/general/">AutoRob #general channel</a>

<h2>Prerequisites</h2> 

<p>
This course has recommended prerequisites for "Linear Algebra" and "Data Structures and Algorithms", or permission from the instructor.
</p>

<p>
Programming proficiency: EECS 281 or proficiency in data structures and algorithms should provide an adequate programming background for the projects in this course.  Interested students should consult with the course instructor if they have not taken EECS 281 or its equivalent, but have some other strong programming experience.
</p>

<p>
Mathematical proficiency: Math 214, 217, 417, 419 or proficiency in linear algebra should provide an adequate mathematical background for the projects in this course.  Interested students should consult with the course instructor if they have not taken one of the listed courses or their equivalent, but have some other strong background with linear algebra.
</p>

<p>
Recommended optional proficiency: Differential equations, Computer graphics, Computer vision, Artificial Intelligence
</p>

<p>
The instructor will do their best to cover the necessary material, but no guarantees.  Linear algebra will be used extensively in relation to 3D geometric transforms and systems of linear equations.  Computer graphics is helpful for under-the-hood understanding of threejs.  Computer vision and AI share common concepts with this course.  Differential equations are used to cover modeling of motion dynamics and inverse kinematics, but not explicitly required.
</p>

<h2>Textbook</h2>

<p>
The AutoRob course is compatible with both the Spong et al. and Corke textbooks (listed below), although only one of these books is needed.  Depending on individual styles of learning, one textbook may be preferrable over the other.  Spong et al. is the listed required textbook for AutoRob (as well as ME 567) and is supplemented with additional handouts.  The Corke textbook provides broader coverage with an emphasis on intuitive explanation.
</p>

<p>
<a href="http://bcs.wiley.com/he-bcs/Books?action=index&itemId=0471649902&bcsId=2888"><b>Robot Modeling and Control</b></a>
<br>
Mark W. Spong, Seth Hutchinson, and M. Vidyasagar
<br>
Wiley, 2005 
<br>
<a href="http://www.amazon.com/Robot-Modeling-Control-Mark-Spong/dp/0471649902">Available at Amazon</a>

<p>
<h3>Alternate textbook</h3>
<p>

<a href="http://www.springer.com/us/book/9783642201431"><b>Robotics, Vision and Control: Fundamental Algorithms in MATLAB</b></a>
<br>
Peter Corke
<br>
Springer, 2011


<p>
<h3>Optional texts</h3>
<p>

<a href="http://shop.oreilly.com/product/9780596517748.do"><b>JavaScript: The Good Parts</b></a>
<br>
Douglas Crockford
<br>
O'Reilly Media / Yahoo Press, 2008

<p>
<a href="http://mitpress.mit.edu/books/principles-robot-motion"><b>Principles of Robot Motion</b></a>
<br>
Howie Choset, Kevin M. Lynch, Seth Hutchinson, George A. Kantor, Wolfram Burgard, Lydia E. Kavraki, and Sebastian Thrun
<br>
MIT Press, 2005


<h2>Projects and Grading</h2>

<p>
The AutoRob course will assign 7 projects (6 programming, 1 oral).  AutoRob projects are graded as “checked” (completed) or “due” (incomplete). Prior to being assigned, upcoming projects will have the status of "pending."  In terms of workload, each project is expected to take approximately 4 hours of work on average (as a rough estimate).  
</p>

<p>
Individual final grades are assigned based on the sum of points earned from coursework (detailed in subsections below). Based on this sum, an overall grade for the course is earned as follows: An "A" grade in the course is earned if graded coursework sums to 93 points or above; A "B" grade in the course is earned if graded coursework sums to 83 points or above; a "C" grade in the course is earned if graded coursework sums to 73 points or above.  The instructor reserves the option to assign appropriate course grades with plus or minus modifiers.
</p>

<p>
The timing and due dates for course projects and quizzes will be announced on an ongoing basis.  All assignments checked by the end of classes.
</p>

<h3>EECS 398-002: Introduction to Autonomous Robotics</h3>

<p>
Beyond AutoRob projects, EECS 398-002 will additionally have 4 short quizzes. Each completed project is weighted as 13 points and each correctly answered quiz question is weighted as 1 point.  Each quiz will consist of 5 short questions that will be within the scope of previously graded projects.  In other words, each quiz question should be readily answerable given knowledge from correctly completing projects that have been assigned.
</p>

<!--???<a href="https://www.michigandaily.com/content/viewpoint-qwizdom-can-help">pop quiz</a>--> 

<h3>EECS 598-010: Robot Modeling and Control</h3>

<p>
EECS 598-010 will have advanced requirements for each AutoRob project.  Each completed project is weighted as 15 points.  The advanced project requirements will be specified with each assignment.  Examples advance requirements include implementation of RK4 numerical integration for a double pendulum, inverse kinematics by Cyclic Coordinate Descent, and one additional motion planning algorithm.
</p>




<h3>Project Submission and Regrading</h3>

<p>
Git repositories will be used for project implementation, version control, and submission. Project implementations are submitted as branches in your assigned repository. These branches must be submitted prior to the due date for each assignment. Your implementation will be checked out and executed by the course staff. You will be notified by the course staff whether your implementation is sufficient for checking off the assignment. If your assignment is insufficient for receiving a check, you are allowed one regrade (per assignment) with 2 weeks of notification. If deemed necessary, the course staff may require an interactive demonstration of your implementation and/or a web-based written report.
</p>

<h3>Final Grading</h3>

<p>
All grading will be finalized on April 22, 2016.  Regrading of specific assignments will be done upon request during office hours.  No regrading will be done after grades are finalized.

<h3>Repositories</h3>

<p>
You are expected to provide a <b>private</b> git repository for your work in this course with the course instructor added as a read/write collaborator.  If needed, the course staff can assist in the setup of an online git repository through providers such as <a href="https://github.com/">github</a> or <a href="https://bitbucket.org/">bitbucket</a>.  

<!--
Your repository is expected to have the following subdirectories, at a minimum, as well as the file "grading.txt" with your updated course grading status:
</p>

<p class="indented">
<b>p_project</b>: containing implementation and build and execution instructions for the preparatory project<br>
<b>reviews</b>: containing reviews of assigned papers in plain text format<br> 
<b>presentation</b>: containing paper presentation slides in PDF format<br>
<b>proposal</b>: containing final project proposal in plain text format<br>
<b>f_project</b>: containing final project implementation and slides (in PDF format) <br>
</p> 
-->

<p>
Please refer to the <a href="http://www.git-scm.com/book/en/v2">Pro Git book</a> for an in-depth introduction to git and version control.  As different people often learn through different styles, the <a href="http://www-cs-students.stanford.edu/~blynn/gitmagic/">Git Magic tutorial</a> has also proved quite useful when a different perspective is needed.  <a href="http://rogerdudler.github.io/git-guide/">git: the simple guide</a> has often been a great and accessible quick start resource. 
</p>

<p>
We expect students to use these repositories for collaborative development as well as project submission. It is the responsibility of each student group to ensure their repository adheres to the Collaboration Policy and submission standards for each assignment. Submission standards and examples will be described for each assignment as needed.
</p>

<h3>Late Policy</h3>
<p>
Do not submit assignments late.  The course staff reserves the right to not grade late submissions.  


<h3>Collaboration Policy</h3>
<p>
 This policy covers all course material and assignments unless otherwise stated. Course material, concepts, and documentation may be discussed with anyone.  Assignments may be discussed with the other students at the conceptual level.  Discussions may make use of a whiteboard or paper.  Discussions with others (or people outside of your assigned group) cannot include writing or debugging code on a computer or collaborative analysis of source code that is not your own. You may take notes away from these discussions, provided these notes do not include any source code.
</p>

<p>
The code for your implementation may not be shown to anyone outside of your group, including granting access to repositories or careless lack of protection. You do not need to hide the screen from anyone, but you should not attempt to show anyone your code. When you are done using any robot device such that another group may use it, you must remove all code you have put onto the device. You may not share your code with others outside of your group. At any time, you may show others the implemented program running on a device or simulator, but you may not discuss specific debugging details about your code while doing so.
</p>

<p>
This policy applies not only applies to collaboration during the current semester, but also any past or future instantiations of this course.  Although course concepts are intended for general use, your implementation for this course must remain private after the completion of the course.  It is expressly prohibited to share any code previously written and graded for this course with students currently enrolled in this course.  Similarly, it is expressly prohibited for any students currently enrolled in this course to refer to any code previously written and graded for this course.
</p>

<p>
Should you fail to abide by this policy, you will receive no credit for this course.  The University of Michigan reserves the right to pursue any means necessary to ensure compliance. This includes, but is not limited to prosecution through The College of Engineering’s Honor Council, which can result in your suspension or expulsion from the University of Michigan.  Please refer to the <a href ="http://ossa.engin.umich.edu/honor-council/">Engineering Honor Council</a> for additional information.
</p>

<h2 id="schedule">Course Schedule (tentative and subject to change)</h2>

<table cellpadding=5 border=0  width="100%">
<tr bgcolor="#dddddd">     
        <th style="width:40px"><b><center>Date</center></b></th> 
        <th style="width:500px"><b><center>Topic</center></b></th>
        <th style="width:150px"><b><center>Reading</center></b></th>
        <th style="width:200px"><b><center>Project</center></b></th>
</tr>

<tr>
    <td><b>Jan 6</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_01_initialization.pdf">Initialization</a>: Course overview, Project overview, Some robotics history<br>
    </td>
    <td>Spong Ch.1<hr>Corke Ch.1</td> 
    <td></td> 
</tr>

<!--
<tr>
    <td><b>Jan 8</b></td>
    <td>
         <a href="slides will go here">JavaScript and git tutorial</a> <br>
    </td>
    <td>Crockford</td> 
    <td></td> 
</tr>
-->

<tr bgcolor="#dddddd">     
<td></td><td>Week 2</td><td></td><td></td>
</tr>

<tr>
    <td><b>Jan 11</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_02_tutorial.pdf">JavaScript and git tutorial</a> <br>
    </td>
    <td>Crockford <br><br>
    HTML5/JS examples <a href="examples/hello.html">hello</a><br> 
    and <a href="examples/hello_anim.html">hello_anim</a> </td> 
    <td></td> 
</tr>

<tr>
    <td><b>Jan 13</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_03_dynamics_pendulum.pdf">Simple Pendulum</a>: Cartesian vs. Generalized coordinates, Lagrangian equation(s) of motion<br>
    </td>
    <td>Spong 7.1-3<hr>Corke 9.1-3</td> 
    <td>Out: <a href="#assignment1">Getting Started</a></td> 
</tr>

<tr>
    <td><b></b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_03_dynamics_pendulum.pdf">Numerical Integrators</a>: Initial value problem, Integrators: Euler, Verlet, Runge-Kutta 4<br>
    </td>
    <td>
        <a href="https://en.wikipedia.org/wiki/Euler_method">Handout 1</a>,
        <a href="https://en.wikipedia.org/wiki/Verlet_integration">2</a>,
        <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#The_Runge.E2.80.93Kutta_method">3</a>
    </td> 
    <td>Out: <a href="#assignment2">Pendularm</a></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 3</td><td></td><td></td>
</tr>

<tr>
    <td><b>Jan 18</b></td>
    <td>
         <a href="http://www.history.com/topics/black-history/martin-luther-king-jr">Martin Luther King Jr. Day</a>: Help broaden participation in computing and robotics <br>
    </td>
    <td></td> 
    <td></td> 
</tr>


<tr>
    <td><b>Jan 20</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_04_control_pid.pdf">Motion Control</a>: Open-loop vs. Closed-loop control, PID control<br>
    </td>
    <td>Spong 6.3<hr><a href="http://www.cds.caltech.edu/~murray/courses/cds101/fa02/caltech/astrom-ch6.pdf">Handout</a></td> 
    <td>Due: Getting Started</td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 4</td><td></td><td></td>
</tr>

<tr>
    <td><b>Jan 25</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_05_linear_refresh.pdf">Linear Algebra Refresher</a>: Systems of linear equations, Vector operations, Matrix operations<br>
         <!-- FUTURE: move FK here -->
    </td>
    <td>Spong A-B<hr>Corke D</td> 
    <td></td> 
</tr>

<tr>
    <td><b>Jan 27</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_06_fk_matrixstack.pdf">Forward Kinematics</a>: Kinematic chains, URDF kinematic specification, matrix stack traversal, DH parameters<br>
         <!-- FUTURE: cover Newton-Euler here -->
    </td>
    <td>Spong 3.1-2<hr>Corke 7.1-2</td> 
    <td>Due: Pendularm<br>Out: <a href="#assignment3">Forward Kinematics</a></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 5</td><td></td><td></td>
</tr>

<tr>
    <td><b>Feb 1</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_07_fk_quaternions.pdf">Quaternions</a>: Euler angles, Gimbal lock, Axis-angle rotation, Matrix stack with joint controls
    </td>
    <td>
        <a href="https://en.wikipedia.org/wiki/Gimbal_lock">Handout 1</a>, 
        <a href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">2</a>
        <hr>
        Corke 2.2-3
    </td> 
    <td></td> 
</tr>


<tr>
    <td><b>Feb 3</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_08_fsm_subsumption.pdf">Reactive Controllers</a>: Reactive and Deliberative Decision Making, Finite State Machines, Subsumption Architecture<br>
    </td>
    <td></td> 
    <td></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 6</td><td></td><td></td>

</tr>

<tr>
    <td><b>Feb 8</b></td>
    <td>
         <a href="slides will go here">3D Point Cloud Segmentation</a>: Robot Middleware, ROS, <i>rosbridge</i>, Point Clouds, Principal Components Analysis, Connected Components
    </td>
    <td>
        <a href="http://arxiv.org/pdf/1404.1100.pdf">PCA</a><br>
<a href="http://www.willowgarage.com/sites/default/files/Rusu08RAS-Semantic.pdf">Rusu 2008 (Sec 4.2)</a> <br>
<a href="http://ohseejay.org/papers/rctoris_iros2015.pdf">Toris 2015</a>
    </td> 
    <td></td> 
</tr>


<tr>
    <td><b>Feb 10</b></td>
    <td>
         398-002: Quiz 1 <hr> 598-010: Robot Simulation Session
    </td>
    <td><a href="https://scratch.mit.edu/projects/10607750/">IK robot game</a></td> 
    <td>Due: Forward Kinematics<br>Out: <a href="#assignment4">Dance Contest</a></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 7</td><td></td><td></td>

</tr>

<tr>
    <td><b>Feb 15</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_10_ik_closedform.pdf">Inverse Kinematics 1 - Closed-form</a>: Joint vs. Endeffector control, Planar 2-link arm, Closed form solutions, Cyclic Coordinate Descent<br>
    </td>
    <td>Spong 3.3<hr>Corke 7.3</td> 
    <td></td> 
<tr>


<tr>
    <td><b>Feb 17</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_11_ik_jacobian.pdf">Inverse Kinematics 2 - Manipulator Jacobian</a>: Gradient descent, Manipulator Jacobian, Jacobian transpose, pseudoinverse
    </td>
    <td>Spong Ch. 4 <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=86079">Wang, Chen 1991</a><hr>Corke Ch. 8</td> 
    <td></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 8</td><td></td><td></td>

</tr>

<tr>
    <td><b>Feb 22</b></td>
    <td> 
         <a href="slides will go here">Bug Algorithms</a>: Reaction vs. Deliberation, Bug0, Bug1, Bug2, Tangent Bug</a> 
         <!--<a href="slides will go here">Real robot display and control</a>: rosbridge protocol, Robot Operating System, subscribing/publishing joint state -->
    </td> 
    <td>
    Corke Ch. 5
    </td> 
<tr>

<tr>
    <td><b>Feb 24</b></td>
    <td>
         398-002: Extended office hours  <hr> 598-010: Robot simulation session
    </td>
    <td></td> 
    <td>Due: Dance Contest<br>Out: <a href="#assignment5">Inverse Kinematics</a></td> 
<tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 9: Spring Break</td><td></td><td></td>

</tr>

<tr>
    <td> </td>
    <td><b>Feb 29 - Mar 4</b></td>
    <td> </td>
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 10</td><td></td><td></td>

</tr>

<tr>
    <td><b>Mar 7</b></td>
    <td>
         <a href="slides will go here">Path Planning</a>: A-star grid search, Potential fields, Wavefront planning</a>
    </td>
    <td>Spong Ch. 5 </td> 
    <td></td>
<tr>

<tr>
    <td><b>Mar 9</b></td>
    <td>398-002: Quiz 2 <hr>598-010: Newton-Euler recursion

</td>
    <td>
    </td> 
<tr>


<tr bgcolor="#dddddd">     
<td></td><td>Week 11</td><td></td><td></td>

</tr>

<tr>
    <td><b>Mar 14</b></td>
    <td>
         <a href="slides will go here">Configuration Spaces</a>: Workspaces vs. Configuration spaces, Minkowski sum</a>
    </td>
    <td></td> 
<tr>

<tr>
    <td><b>Mar 16</b></td>
    <td>
         <a href="slides will go here">Motion Planning</a>: Probabilistic roadmaps, Rapidly-exploring Random Trees, RRT-Connect motion planning (Kuffner/LaValle)
    </td>
    <td><a href="https://personalrobotics.ri.cmu.edu/files/courses/papers/Kuffner00-rrtconnect.pdf">Kuffner, LaValle 1999</a></td> 
    <td>Due: Inverse Kinematics<br>Out: <a href="#assignment6">Motion Planning</a></td> 
<tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 12: No class - off-site meeting</td><td></td><td></td>

</tr>
<tr>
    <td></td>
    <td><b>Mar 21-23</b></td>
<tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 13</td><td></td><td></td>

</tr>

<tr>
    <td><b>Mar 28</b></td>
    <td>
         Quiz 3, <a href="slides will go here">Collision Detection</a>: Axis-Aligned Bounding Boxes, Separating Axis Theorem 
    </td>
    <td><a href="https://wwwx.cs.unc.edu/~walk/papers/gottscha/sig96.pdf">Gottschalk et al. 1996</a></td> 
<tr>

<tr>
    <td><b>Mar 30</b></td>
    <td>
         <a href="slides will go here">Simultaneous Localization and Mapping</a>: Robot odometry, Laser rangefinding, Loop closure, SGD-SLAM paper (Olson et al.)
    </td>
    <td><a href="https://april.eecs.umich.edu/pdfs/olson2006icra.pdf">Olson et al. 2006</a></td> 
    <td></td>
<tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 14: <a href="http://www.nationalroboticsweek.org/">National Robotics Week</a></td><td></td><td></td>

</tr>

<tr>
    <td><b>Apr 4</b></td>
    <td>
         <a href="slides will go here">Robot Localization</a>: Bayes rule, Bayesian filtering, Monte Carlo Localization (Dellaert et al.)
    </td>
    <td><a href="http://www.cc.gatech.edu/~dellaert/pub/Dellaert99icra.pdf">Dellaert et al. 1999</a></td> 
<tr>

<tr>
    <td><b>Apr 6 </b></td>
    <td>
         <a href="slides will go here">RGBD Mapping</a>: Depth cameras, 3D point cloud processing, Iterative Closest Point algorithm, 3D mapping (Fox et al.)
    </td>
    <td><a href="https://www.willowgarage.com/sites/default/files/Rusu08RAS-Semantic.pdf">Rusu et al. 2008</a></td> 
    <td>Due: Motion Planning<br>Out: <a href="#assignment7">Best Use of Robotics</a></td> 
<tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 15</td><td></td><td></td>

</tr>

<tr>
    <td><b>Apr 11</b></td>
    <td>
         Quiz 4, <a href="slides will go here">Scene Estimation</a>: Symbolic task planning, Sequential mobile manipulation, Axiomatic Particle Filtering (Sui et al.)
    </td>
    <td><a href="http://ohseejay.org/papers/zsui_iros2015.pdf">Sui et al. 2015</a></td> 
<tr>

<tr>
    <td><b>Apr 13</b></td>
    <td>In-class presentations</td>
    <td></td>
    <td>Due: Best Use of Robotics</td> 
<tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 16</td><td></td><td></td>

</tr>

<tr>
    <td><b>Apr 18</b></td>
    <td>Regrading session</td>
<tr>

<tr>
    <td><b>Apr 22</b></td>
    <td>Grading finalized</td> 
<tr>






</table>


<p>
Slides from this course borrow from and are indebted to many sources from around the web.  These source include a number of excellent robotics courses:

<ul>
<li><a href="http://www-clmc.usc.edu/teaching/introductiontorobotics">USC CS 545: Introduction to Robotics</a></li>
<li><a href="https://cirl.lcsr.jhu.edu/SensorBasedRobotics/">JHU 600.336 - Algorithms for Sensor-Based Robotics</a></li>
</ul>

<h2 id="assignment1">Assignment 1: Getting Started (Warm up)</h2>  
<p>
<b>Due 1pm, Wednesday, January 20, 2016</b>
</p>
<p>
In this assignment, you should clone the <a href="https://github.com/ohseejay/kineval-stencil">kineval_stencil</a> repository into your working repository for the course.  kineval_stencil contains a code template for this assignment as well as all projects in the course.  If you open "home.html" in this repository, you should see the jittering disconnected pieces of a robot (described in "robots/mr2.js"), similar to the snapshot below.  This initial mode is the "starting point" state of the stencil to help build familiarity with JavaScript/HTML5 and KinEval.
</p>
<img width=100% src="images/kineval_welcome.png">

<p>
Your task is to make these objects in starting point mode responsive to keyboard commands.  Specifically, these objects will move upward, stop/start jittering, move closer together, and further apart (although more is encouraged).  To do this, you will modify "kineval/kineval_startingpoint.js" at the sections marked with "STENCIL".  These sections also include code examples meant to be a quick (and very rough) introduction to JavaScript, assuming programming competency in another language. 
</p>

<h3>Brief Code Overview</h3>
<p>
Within the KinEval stencil, the functions my_animate() and my_init() in "home.html" are the principal access points into animation system.  my_animate() is particularly important as it will direct the invocation of functions we develop throughout the AutoRob course.  my_animate() and my_init() are called by the primary process that maintains the animation loop: kineval.animate() and kineval.init() within "kineval/kineval.js".  <b>IMPORTANT</b>: "kineval/kineval.js", kineval.animate(), and kineval.init() should not be modified.  For starting point mode, my_animate() will call startingPlaceholderAnimate() and startingPlaceholderInit().  startingPlaceholderInit() contains JavaScript tutorial-by-example code that initializes variables for this project. startingPlaceholderAnimate() contains keyboard handlers and code to update the positioning of each body of the robot.  By modifying the proper variables at the locations labed "STENCIL", this code will update the transformation matrix for each geometry of the robot (stored in the ".xform" attribute) as a translation in the robot's world.  The ".xform" transform for each robot geometry is then used by kineval.robotDraw() to have the browser render the robot parts in the appropriate locations.
</p>

</p>

<h3>Project Submission</h3>
<p>
To ensure proper submission of your assignments, please do the following:
</p>
 
<p>
<ul>
<li>email the course instructor (ocj addrsign umich) with your name, email address, and pointer to your repository, </li>
<li>ensure the course instructor knows what repository you are using, and your branch is created and not modified past project deadlines</li>
<li>ensure the instructor (id:ohseejay) has push/admin access to your repository, which can be confirmed/addressed through email or office hours (or by seeing that the instructor has committed the file "grading.txt")</li>
</ul>
</p>

<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-1".  <b>NOTE: spelling matters!</b>  The "Assignment-1" branch is essentially a tag and should not be merged back into the master.  You should continue work from the master branch.
</p>

<h2 id="assignment2">Assignment 2: Pendularm </h2>  
<p>
<b>Due 11:59pm, Thursday, January 28, 2016</b>
</p>

<p>
To get a sense of physical dynamics and control, your task is to implement a physical simulator and servo controller for a frictionless <a href="http://en.wikipedia.org/wiki/Pendulum">simple pendulum</a> with a rigid massless rod, and then control this system as a 1 DOF robot with a single motor.  
</p>

<!-- (uncomment)
The code stencil for the Pendularm assignment is available within the "pendularm" subdirectory of KinEval in the file <a href="https://github.com/ohseejay/kineval-stencil/blob/master/pendularm/pendularm1.html">pendularm1.html</a>.
-->

<p>
<center>
<a href="https://github.com/ohseejay/kineval-stencil/blob/master/pendularm/pendularm1.html"><img width=80% src="images/pendularm.png"></a>
</center>
</p>

<p>
For physical simulation, you will implement several numerical integrators for a pendulum with parameters specified in the code stencil.  The numerical integrator will advance the state (angle and velocity) of the pendulum in time given the current acceleration (generated from the pendulum equation of motion).  If implemented successfully, this ideal pendulum should oscillate about the vertical (where the angle is zero) proportional to the pendulum's initial angle.
</p>

<p>
Students enrolled in EECS 398-002 will implement numerical integrators for:
</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Euler%27s_method">Euler's Method</a> 
<li><a href="http://en.wikipedia.org/wiki/Verlet_integration#Velocity_Verlet">Velocity Verlet</a> 
</ul>

<p>
Students enrolled in EECS 598-010 will implement numerical integrators for:
</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Euler%27s_method">Euler's Method</a> 
<li><a href="https://en.wikipedia.org/wiki/Verlet_integration#Verlet_integration_.28without_velocities.29">Verlet integration</a>
<li><a href="http://en.wikipedia.org/wiki/Verlet_integration#Velocity_Verlet">Velocity Verlet</a>
<li><a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#The_Runge.E2.80.93Kutta_method">Runge-Kutta 4</a>
</ul>

<p>
For motion control, students in both EECS 398-002 and EECS 598-010 will implement a <a href="http://en.wikipedia.org/wiki/PID_controller">proportional-integral-derivative controller</a> to control the system's motor to a desired angle.  This PID controller should output control forces integrated into the system's dynamics.  You will need to tune the gains of the PID controller for stable and timely motion to the desired angle for pendulum with parameters: length=2.0, mass=2.0, gravity=9.81.  
</p>

<p>
For user input, you should be able to select the choice of integrator using the [0-4] keys (with no integration as a default), toggle the invocation of the servo controller with the 'c' key (which is off by default), decrement and increment the desired angle of the 1 DOF servoed robot arm use the 'q' and 'e' keys, and momentarily disable the servo controller with 's' key (and allowing the arm to swing uncontrolled).
</p>

<h3> Project Submission</h3>
<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-2".  
</p>

<h3> Additional Notes</h3>
<p>
Students in EECS 598-010 are strongly encouraged to extend their pendularm to a double pendulum.
</p>

<h2 id="assignment3">Assignment 3: Forward Kinematics</h2>  
<b>Due 11:59pm, Friday, February 12, 2016</b>
<p>
In this assignment, you will render the forward kinematics (FK) of a robot, given its kinematic specification (in the "robots" subdirectory).  To render the robot properly, you will compute matrix transforms for each link and joint of the robot based on the parameters of its hierarchy configuration.  The computation of the matrix transform for each joint and link will allow KinEval's rendering support routines to properly display the full robot.  We will assume the joints will remain in their zero position, saving joint motion for the next assignment.  
</p>

<p>
Assuming proper completion of Assignment 1, ensure the following files are included (within script tags) in your "home.html".  You will modify these files for implementing FK:

<ul>
<li>"kineval/kineval_robot_init.js" for initializing your robot object based on a given description object; modification is require to add parent and child references to each link</li>
<li>"kineval/kineval_forward_kinematics.js" for implementing (a recursive) traversal over joints and links to compute transforms; traversal of forward kinematics is invoked from kineval.robotForwardKinematics() within my_animate() in home.html </li>
 <li>"kineval/kineval_matrix.js" for the implementation of your vector and matrix routines, such as for matrix multiplication, matrix generation, etc. in kineval_matrix.js </li>
</ul>
</p>


<!-- (uncomment) -->
<h3> Robot Examples and Initialization</h3>
<p>
Each file in the "robots" subdirectory contains code to create a robot data object .  This data object is initialized the kinematic description of a robot (as well as some meta information and rendering geometries).  The kinematic description defines a hierarchical configuration of the robot's links and joints.  This description is a subset of the <a href="http://wiki.ros.org/urdf">Unified Robot Description Format (URDF)</a> converted into JSON format.  The basic features of URDF are described in <a href="http://wiki.ros.org/urdf/Tutorials/Create%20your%20own%20urdf%20file">this tutorial</a>.  
</p>

<p>
<b>IMPORTANT:</b> The given robot description files should <b>NOT</b> be modified.  Code that requires modified robot description files will fail tests used for grading.  You are welcomed and encouraged to create new robot description files for additional testing.
</p>

<p>
The selection of file with a robot description can occur directly in the URL for  "home.html".  As a default, the "home.html" in the KinEval stencil assumes the "mr2" robot description in "robots/robot_mr2.js".  Another robot description file can be selected directly in the URL by adding a robot parameter.  This parameter is segmented by a question mark and sets the robot file pointer to a given file local location, relative to "home.html".  For example, a URL with "home.html?robot=robots/robot_urdf_example.js" will use the URDF example description.
</p>

<p>
In addition to the given initialization, you should extend the robot object to complete the kinematic hierarchy to specify the parent and children of each link.  This modification should be made in the kineval.initRobotJoints() function in "kineval/kineval_robot_init.js".  The children array of a link should always be defined, which would result in an empty array for leaf nodes in the kinematic tree.
</p>

<p>
<b>Note</b>: KinEval refers to links and joints as strings, not pointers, within the robot object.  robot.joints (as well as robot.links) is an array of data objects that are indexed by strings.  Each of these objects stores relevant fields of information about the joint, such as its transform (".xform"), parent (".parent") and child (".child") in the kinematic hierarchy, local transform information (".origin"), etc.  As such, robot.joints['JointX'] refers to an object for a joint.  In contrast, robot.joints['JointX'].child refers to a string ('LinkX'), that can then be used to reference a link object (as robot.links['LinkX']).   Similarly, robot.links['LinkX'].parent refers to a joint as a string 'JointX' that can then then be used to reference a joint object in the robot.joints array.
</p>

<h3> Invoking Forward Kinematics</h3>

<p>
The function kineval.robotForwardKinematics() in "kineval/kineval_forward_kinematics.js" will be the main point of invocation for your FK implementation.  This function is responsible for updating matrix transforms for the frame of each link and joint with respect to the global world coordinates.  The computed transform for each frame of the robot needs to be stored in the ".xform" field.  For a given link named 'LinkX', this xform field can be accessed as robot.links['LinkX'].xform.  For a given joint named 'JointX', this xform field can be accessed as robot.joints['JointX'].xform.  Once kineval.robotForwardKinematics() completes, the updated transforms for each frame are used by the function kineval.robotDraw() in the support code to render the robot.
</p>


<p>
A matrix stack recursion can be used to compute these global frames, starting from the base of the robot (specified as a string in robot.base).  This recursion should use local translation and rotation parameters of each joint in relation to its parent link in its traversal of the hierarchy.  For a given joint 'JointX', these translation and rotation parameters are stored in the robot object as robot.joints['JointX'].origin.xyz and robot.joints['JointX'].origin.rpy, respectively.  The current global translation and rotation for the base of the robot (robot.base) in the world coordinate frame is stored in robot.origin.xyz and robot.origin.rpy, respectively.
</p>


<p>
To run your FK routine, you must toggle out of starting point mode.  This toggle can be done interactively within the GUI menu or by setting kineval.params.just_starting to false.  The code below in "home.html" controls starting point mode invocation, where single line can be uncommented to use FK mode by default:
</p>

<pre><code data-language="javascript">
// set to starting point mode is true as default 
//   set to false once starting forward kinematics project
//kineval.params.just_starting = true;

if (kineval.params.just_starting == true) {
    startingPlaceholderAnimate();
    kineval.robotDraw();
    return;
}
</code></pre>



<!-- (uncomment end) -->
<p>
If implemented properly, the "robots/robot_urdf_example.js" example should produce the following rendering:
</p>
<p> <center>
<img  width=50% src="images/fk_urdf_example.png">
</center> <p>

<p>
The "robots/robot_mr2.js" example should produce the following:
</p>
<p> <center>
<img  width=90% src="images/fk_mr2_example.png">
</center> <p>

<p>
The "robots/robot_crawler.js" example should produce the following:
</p>
<p> <center>
<img  width=90% src="images/fk_crawler_example.png">
</center> <p>


<!-- (uncomment) -->
<h3> Interactive Hierarchy Traversal</h3>
<p>
Additionally, a correct implementation will be able to interactively traverse the kinematic hierarchically by changing the active joint.  The active joint has focus for user control, which will be used in the next assignment.  For now, we are using the active joint to ensure your kinematic hierarchy is correct.  You should be able to move up and down the kinematic hierarchy with the "k" and "j" keys, respectively.  You can also move between the children of a link using the "h" and "l" keys.
</p>

<h3> Orienting Joint Rendering Cylinders</h3>
<p>
The cylinders used as rendering geometries for joints are not aligned with joint axes by default.  The support code in Kineval will properly orient joint rendering cylinders.  To use this functionality, simply implement a vector cross product function named vector_cross() in your matrix routines.  vector_cross() will be automatically detected and used to properly orient each joint rendering cylinder.
</p>

<h3> EECS 598-010 Requirement</h3>
<p>
Students in EECS 598-010 must implement the assignment as described above to work with given examples as well as the Fetch robot description.  The file "robots/fetch/fetch.urdf/js" contains the robot data object for the Fetch kinematic description.  This JavaScript file converted from the <a href="https://github.com/fetchrobotics/fetch_ros/blob/indigo-devel/fetch_description/robots/fetch.urdf">Fetch URDF description</a> for ROS.  ROS uses a different default coordinate system than threejs, which needs to be taken into account in the FK computation.  Coordinate frames in ROS assumes that the Z, X, and Y axes correspond to the up, forward, and side directions, respectively.  In contrast, threejs coordinate frames assume the Y, Z, and X correspond to the up, forward, and side directions.  The variable robot.links_geom_imported will be set to true when geometries have been imported from ROS and set to false when geometries are defined completely within the robot description file.
</p>

<p>
A proper implementation for fetch.urdf.js example should produce the following:
</p>
<p> <center>
<img  width=90% src="images/fk_fetch_example.png">
</center> <p>
</p>


<h3> Project Submission</h3>
<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-3".  
<p>
<!-- (uncomment end) -->

<p>

<h2 id="assignment4">Assignment 4: Robot FSM Dance Contest </h2>  
<b>Due 11:59, Friday, February 26, 2016</b>
<p>

<p>
For this assignment, you will now enable your robot to execute a dance routine by adding motor rotation to its joints and creating a Finite State Machine (FSM) controller over pose setpoints.  Your FK implementation will now be extended to consider angular rotation about each joint axis using quaternions for axis-angle rotation.  The positioning of each joint with respect to a given pose setpoint will be controlled by an simple P servo implementation (based on the Pendularm assignment).  You will implement an FSM controller to update the current pose setpoint based on the robot's current state and predetermined sequence of setpoints.  For a single robot, you will choreograph a dance for the robot by creating an FSM with your design of pose setpoints and an execution sequence. 
</p>

<p>
This controller for the "mr2" was a poor attempt at <a href="https://www.youtube.com/watch?v=roBWj9YPKPo">robot Saturday Night Fever</a> (please do better):
</p>

<a href="asgn4_joint_rotation.png"><img width=100% src="images/asgn4_joint_rotation_small.png"></a>

<p>
This <a href="https://www.youtube.com/embed/WyQ9aoB3bpI">updated dance</a> controller for the Fetch robot is a bit better, but still very far from optimal:
</p>

<center>
<iframe width="420" height="315" src="https://www.youtube.com/embed/WyQ9aoB3bpI" frameborder="0" allowfullscreen></iframe>
</center>

<p>
Assuming proper completion of Assignment 3, ensure the following files are included (within script tags) in your "home.html".  You will modify these files for implementing axis-angle rotation, the pose setpoint controller, and the FSM controller:

<ul>
<li>"kineval/kineval_quaternion.js" for your implementation of quaternions for axis-angle rotation in 3D</li>
 <li>"kineval/kineval_forward_kinematics.js" to augment your existing kinematic traversal to account for axis-angle joint rotation</li>
<li>"kineval/kineval_controls.js" includes function kineval.applyControls() to apply a control update to the robot's base and angle of each joint, as well as updating the camera position; this update just does an addition and does not consider a physical model of dynamics</li>
 <li>"kineval/kineval_servo_control.js" for your implementation of a P servo controller and an FSM pose sequencer</li>
</ul>
</p>


<!-- (uncomment) -->
<h3>Joint Axis Rotation and Interactive Control</h3>

<p>
Each joint of the robot needs several additional properties for joint rotation and control.  These joint properties for the current angle rotation (".angle"), applied control (".control"), and servo parameters (".servo") have already been created within the function kineval.initRobotJoints().  The joint's angle will be used to calculate a rotation about the joints (normal) axis of rotation vector, specified in the ".axis" field.  The 3D rotation due to joint movement should be accounted for in the robot's forward kinematics and implemented as quaternions in "kineval/kineval_quaternion.js".
</p>

<p>
If joint axis rotation is implemented correctly, you should be able to use the 'u' and 'i' keys to move the currently active joint.  These keys respectively decrement and increment the ".control" field of the active joint.  Through the function kineval.applyControls(), this control value effectively adds an angular displacement to the joint angle.
</p>

<h3>Interactive Base Movement Controls</h3>

<p>
The user interfaces also enables controlling the global position and orientation of the robot base.  In addition to joint updates, the system update function kineval.applyControls() also updates the base state (in robot.origin) with respect to its controls (specified in robot.controls).  With the support function kineval.handleUserInput(), the 'wasd' keys are purposed to move the robot on the ground plane with 'q' and 'e' keys for lateral base movement.  In order for these keys to behave properly, the heading and lateral directions of the robot base are needed such that they respectively express coordinates along local z-axis and x-axis of the base in the global frame.  These vectors need to be computed within your FK implementation and stored within two global variables: robot_heading and robot_lateral.  Each of these variables should be a homogeneous 3D vector stored as a 2D array.
</p>

<p>
If robot_heading and robot_lateral are implemented properly, the robot should now be interactively controllable in the ground plane.
</p>

<h3>Pose Setpoint Controller</h3>

<p>
Once joint axis rotation is implemented, you will implement proportional setpoint controller for the robot joints in function kineval.robotArmControllerSetpoint() within "kineval/kineval_servo_controller.js".  This setpoint controller uses the current angle (".angle"), desired angle, and servo gains (specified in the ".servo" object) of each joint to output a control (".control") for the joint.  The desired angle for a joint 'JointX' is stored in kineval.params.setpoint_target['JointX'] as a scalar. All of these joint object properties are initialized in the function kineval.initRobotJoints() in "kineval/kineval_robot_init.js".
</p>

<p>
For testing, a "clock movement" controller has been provided as the function setpointClockMovement() in "kineval/kineval_setpoint_controller.js".  This function can be invoked by holding down the 'c' key or from the UI.  This controller goes well with <a href="https://www.youtube.com/watch?v=_JPa3BNi6l4"> this song</a>.
</p>

<p>
The robot can servo to the current pose setpoint by holding down the 'o' key or selecting 'persist_pd' from the UI.  Pressing the '0' key sets the current setpoint to the zero pose, where all joint angles are zero.  Stored in kineval.setpoints, up to 9 other arbitrary pose setpoints can be stored by KinEval for pose control.  The current robot pose can be interactively stored by pressing "Shift+number_key" (e.g., "Shift+1").  The current setpoint can be assigned a stored pose by pressing one of the non-zero number keys [1-9].  At any time, the currently stored setpoints can be output to the console as JavaScript code using the JSON.stringify function for the setpoint object, as the statement "JSON.stringify(kineval.setpoints);".  This setpoint array can be included in your code as part of your dance controller.
</p>

<h3>FSM Controller</h3>

<p>
Once your pose setpoint controller is working, a FSM controller should be implemented in the function kineval.setpointDanceSequence() in "kineval/kineval_setpoint_control.js".  The reference implementation uses pose setpoints initialized and stored in kineval.setpoints with a sequence of indices stored in kineval.params.dance_sequence_index and playback index stored in kineval.params.dance_pose_index.  If this convention is not used, the following line in "kineval/kineval_userinput.js" will require modification:
<p>

<pre><code data-language="javascript">
if (kineval.params.update_pd_dance)
    textbar.innerHTML += "executing dance routine, pose " + kineval.params.dance_pose_index + " of " + kineval.params.dance_sequence_index.length;
</code></pre>

<h3> EECS 598-010 Requirements</h3>
<p>
Students in EECS 598-010 must implement the assignment as described above for the Fetch robot with two additional requirements: 1) proper enforcement of joint types and limits for Fetch robot description, and 2) integration of their code with ROS or a <a href="http://docs.fetchrobotics.com/gazebo.html">Gazebo simulation of the Fetch</a> using <a href="http://wiki.ros.org/rosbridge_suite">rosbridge</a>.  

<p>
The Fetch URDF JS file, included in the provided code stencil, contains joints with with various types that correspond to different types of motion:
</p>

<p>
<ul>
<li>continuous: rotation about the joint axis with no joint limits</li>
<li>revolute: rotation about the joint axis with joint limits</li>
<li>prismatic: translation along the joint axis with joint limits</li>
<li>fixed: no motion of the joint</li>
</ul>
</p>

<p>
Joints are considered to be continuous as the default.  Joints with undefined motion types must be treated as continuous joints.
</p>

<p>
Your code can interface with a robot (or simulated robot) running rosbridge/ROS using the function kineval.rosbridge() in "kineval/kineval_rosbridge.js".  This code requires that the rosbridge_server package is running in a ROS run-time environment and listening on a websocket port, such as for ws://fetch7:9090.  If your FK implementation is working properly, the model of your robot in the browser will update along with the motion of the robot based on the topic subscription and callback.  This functionality works seamlessly between real and simulated robots.  To control the robot, a rosbridge publisher must be written to update the ROS topic "/arm_controller/follow_joint_trajectory/goal" with a message of type "control_msgs/FollowJointTrajectoryActionGoal".
</p>

<p>
Machines running rosbridge, ROS, and Gazebo for the Fetch will be available during special sessions of the class.  Students are encouraged to install and run the Fetch simulator on their own machines based on <a href="http://docs.fetchrobotics.com/gazebo.html">this tutorial</a>.
</p>


<h3>Project Submission</h3>
<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-4" and post a video of your dance controller in action to the course discussion channel.
</p>

<p>
<!-- (comment end) -->


<p>

<hr>
<h1> Assignments beyond this point have not been assigned.  The descriptions below are unofficial and tentative.</h1>
<hr>



<h2 id="assignment5">Assignment 5: Inverse Kinematics </h2>  
<p>
<b>Due 9am, Wednesday, March 16, 2016</b>
<p>

For this assignment, you will now control your robot to reach to a given point through inverse kinematics for position control of the robot endeffector.  Inverse kinematics will be implemented through both the Jacobian Transpose and Jacobian Pseudoinverse methods, although only one will be invoked at run-time.  
<p>

<img src="images/kineval_snapshot_2.png" width=100%>

<iframe width="420" height="315" src="https://www.youtube.com/embed/ag0j8HzFRzc" frameborder="0" allowfullscreen></iframe>

<!-- (uncomment)
The core of this assignment is to complete the kineval.inverseKinematics() function invoked from home.html.  This function will be called with three arguements: the variable ik_target (used by kineval_userinput.js) to specify the IK target location in the world frame, the name of the joint directly connected to the endeffector, and the location of the endeffector in the local joint frame.  The following is an example of invoking kineval.inverseKinematics():

<pre><code data-language="javascript">
    kineval.inverseKinematics(ik_target, "forearm_right_yaw", [[0],[0],[0.5],[1]]);
</code></pre>

<p>
The top level of kineval.inverseKinematics() is provided below, and is the beginning of your implementation in the file kineval_inverse_kinematics.js:  


<p>
<pre><code data-language="javascript">
function robot_inverse_kinematics(target_pos, endeffector_joint, endeffector_local_pos) {
    // compute joint angle controls to move location on specified link to Cartesian location
    if (update_ik) {
        iterate_inverse_kinematics(target_pos, endeffector_joint, endeffector_local_pos);
        endeffector_geom.visible = true;
        target_geom.visible = true;
    }
    else {
        endeffector_geom.visible = false;
        target_geom.visible = false;
    }
    update_ik = false;

}
</code></pre>
<p>

This code stub contains clauses to handle rendering of the endeffector (endeffector_geom) and target (target_geom) geometries and when to perform IK iterations (which occurs while holding down the 'p' key through kineval_userinput.js).  Both endeffector_geom and target_geom have been previously created by kineval, so your code only needs to set the transform using simpleApplyMatrix() for proper rendering.  Further, the 'r'/'f' keys will move the target location up/down, respectively.

<p>
In implementing this IK routine, please remember the following:
<p>
<ul>
<li>Computation of the Jacobian should only occur with respect to the joints along the chain from the endeffector joint to the robot base</li>
<li>The location of the endeffector needs to be computed using transforms resulting from the robot's forward kinematics  </li>
<li>Matrix inversion can be invoked by using the provided routine numeric.inv(mat), available through <a href="http://www.numericjs.com/">numericjs</a> </li>
<li>The computed velocity in configuration should be applied to the robot through the joint.controls field of each joint </li>
<li>This assignment is only for positional control of the robot endeffector with respect to computing IK error</li>
</ul>

<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-5".  
<p>
(comment end) -->

<h2 id="assignment6">Assignment 6: Motion Planning  </h2>  
<p>
<b>Due 9am, Wednesday, April 6, 2016</b>
<p>


For this assignment, you will now implement a collision-free motion planner to enable your robot to navigate from a random configuration in the world to its home configuration (marked by the "X" on the world floor).  Motion planning will be implemented through the <a href="https://personalrobotics.ri.cmu.edu/files/courses/papers/Kuffner00-rrtconnect.pdf">RRT-Connect algorithm</a> (described by Kuffner and LaValle).  

<img src="images/asgn6_motionplan.png"  width=100%>
<p>

<!-- (uncomment)
The core of this assignment is to complete the robot_rrt_planner_init() and robot_rrt_planner_iterate() in the provided kineval_rrt_connect.js stencil.  For successful execution, your implementation of RRT-Connect, the provided collision detection system, and a single specification of world geometry will need to be included in home.html:


<pre><code data-language="javascript">
<script src="kineval_rrt_connect.js"></script> 
<script src="kineval_collision.js"></script> 
<script src="worlds/world_basic.js"></script>
<-
<script src="worlds/world_empty.js"></script>
<script src="worlds/world_random.js"></script>
<script src="worlds/world_local_minima.js"></script>
<script src="worlds/world_s.js"></script>
->
</code></pre>

<p>
To ensure these worlds are rendered in the display, the geometries of the world are added to the threejs scene by calling kineval.setPlanningScene() in home.html at the end of the init_robot() function:

<pre><code data-language="javascript">
function init_robot() {
    ...
    // set scene for planner
    kineval.setPlanningScene();
}
</code></pre>

<p>

Note: your planner should be constrained such that the search does not consider configurations where the base is outside the X-Z plane.  Specifically, the base should not translate along the Y axis, and should not rotate about the X and Z axes.

<h3>First step: add collision detection</h3> 
<p>
Your RRT-Connect implementation will depend on detection of collisions (provided by the function kineval.isCollision() in kineval_collision.js) with respect to a specified world geometry.  Worlds are specified as a rectangular boundary and sphere obstacles.  A collection of worlds are provided in the "worlds/" subdirectory of kineval_stencil.  The collision detection system performs two forms of tests: 1) testing of the base position of the robot against the rectangular extents of the world, and 2) testing of the robot configuration against spherical objects.  Configuration collision testing is performed by AABB/Sphere tests that require the bounding box of each link's geometry in the coordinates of that link.  This bounding box is computed by adding the following within the loop inside init_robot_links_geoms() in kineval.js:

<pre><code data-language="javascript">
        // bounding box of robot link in local link coordinates
        robot.links[x].bbox = new THREE.Box3;
        robot.links[x].bbox = robot.links[x].bbox.setFromPoints(robot.links[x].geom.geometry.vertices);
</code></pre>

(end comment) --> 

<p>
Even before your planner is implemented, you can use the collision system interactively with your robot.  The provided kineval.isCollision() function will test the current configuration of the robot.  If a collision occurs, the base of the robot will be displayed as a solid red.  The call to kineval.isCollision() should be placed within my_animate() in home.html:

<pre><code data-language="javascript">
    // show if robot is currently in collision
    kineval.isCollision();
</code></pre>

<p>
<img src="images/asgn6_collision.png" width=70%>
<p>

<!-- (uncomment)

<h3>Updating kineval_collision for your implementation</h3>
<p>
You will need to modify the forward kinematics calls in kineval_collision.js.  kineval_collision.js uses matrix and quaternion calls based on the reference implementation (i.e., my code).  Your matrix and quaternion calls likely have a different structure to the function arguments and returned data structures.  You should either:

 <ul> 
  <li>1) modify calls to matrix/quaternion routines to fit your functions, or

  <li>2) use a modified version of your own FK with the collision test added to the link traversal function (remember: you need the inverse of the matrix stack for collision testing in a link frame)
</ul>
<p>

Also, you can feel free to use numeric.inv() instead of matrix_invert_affine().  Affine transforms can be inverted (in constant time) through a much simpler process than the generic matrix inversion, which is O(n^3) for Gaussian elimination. 
<p>
If successful to this point, you should be able to see the collision world of the robot, move around this world, and see the base display solid red when a collision occurs.
<p>


<h3>Invoking the planner</h3> 

<p>
Your planner will be invoked interactively by first moving the robot to an arbitrary non-colliding configuration in the world and then pressing the "m" key.  The "m" key will request the generation of a motion plan.  While the planner is working, it will not accept new planning requests.  Thus, you can move the robot around while the planner is executing.

<p>
Invokation of the planner is implemented by adding the following code segments to: 

<p>
<ul>
<li> init_robot() in home.html:

<p>
<pre><code data-language="javascript">
    // initialize flags for executing planner
    generating_motion_plan = false;
    generate_motion_plan = false;
</code></pre>

<p>
<li> my_animate() in home.html:

<p>
<pre><code data-language="javascript">
    // configuration space motion planning
    if ((generate_motion_plan) && (!generating_motion_plan)) {
        robot_rrt_planner_init();
        generating_motion_plan = true;
        generate_motion_plan = false;
    }
    if (generating_motion_plan) {
        //robot_rrt_connect(q_desired);
        rrt_result = robot_rrt_planner_iterate();
        if (rrt_result === "reached") {
            //alert("home: reached");
            generating_motion_plan = false;
        }
    }
</code></pre>

<p>
<li> user_input() in kineval_userinput.js:

<p>
<pre><code data-language="javascript">
    // generate motion plan
    if ( keyboard.pressed("m") )
        generate_motion_plan = true;
    else
        generate_motion_plan = false;
</code></pre>
</ul>

<h3>Planner output</h3> 
<p>
The output of your planner will be a sequentially ordered array (named robot_path[]) of RRT vertices, where each RRT vertex contains a robot configuration (.vertex), an array of edges (.edges), and a threejs indicator geometry (.geom).  The kineval_rrt_connect.js stencil has provide routines that describe how new vertices can be added to the RRT.  One a viable motion plan is found, this path can be highlighted by changing the color of the RRT vertex geom indicators, similar to the following:

<pre><code data-language="javascript">
        robot_path[i].geom.material.color = {r:1,g:0,b:0};
</code></pre>
<p>

The user should should be able to interactively move the robot through the found plan.  After adding the following code below to user_input() in kineval_userinput.js, the "n" and "b" keys to move the robot to the next and previous configuration in the found path, respectively.

<pre><code data-language="javascript">
    // traverse generated motion plan
    if ( keyboard.pressed("n") |  keyboard.pressed("b")) {
        if (typeof robot_path !== 'undefined') {

            // increment index
            if ((keyboard.pressed("n"))&&(robot_path_traverse_idx &lt robot_path.length-1))
                robot_path_traverse_idx++;

            if ((keyboard.pressed("b"))&&(robot_path_traverse_idx &gt 0))
                robot_path_traverse_idx--;

             // set angle
            robot.origin.xyz = [
                robot_path[robot_path_traverse_idx].vertex[0],
                robot_path[robot_path_traverse_idx].vertex[1],
                robot_path[robot_path_traverse_idx].vertex[2]
            ];

            robot.origin.rpy = [
                robot_path[robot_path_traverse_idx].vertex[3],
                robot_path[robot_path_traverse_idx].vertex[4],
                robot_path[robot_path_traverse_idx].vertex[5]
            ];

            for (x in robot.joints) {
                //q_names[x] = q_start_config.length;
                robot.joints[x].angle = robot_path[robot_path_traverse_idx].vertex[q_names[x]];
            }
        }
    }
</code></pre>

Note: we are <b>NOT</b> using robot.controls to execute the found path of the robot.  Although this can be done, the collision system does not currently test for configurations that occur due to the motion between configurations.

<h3>Testing</h3>

<p>
<img src="images/asgn6_scurve_small.png" width=100%>

<p>
Make sure to test from a reasonable set of robots and initial configurations within all of the provided worlds, ensuring that:

<p>
<ul>
<li> a valid non-colliding path is found and can be traversed
<li> the robot does not to take steps longer than 1 unit
<li> the robot base does not move outside the X-Z plane.  Specifically, the base should not translate along the Y axis, and should not rotate about the X and Z axes.
</ul>

<p>
The "mr2" robot should be able to navigate all of the provided worlds.

<h3>Optional: HTML5 Canvas Stencil </h3>

<img width=100% src="images/asgn6_rrt_canvas_stencil_small.png">

<p>
Using the browser for as a development environment has many benefits.  However, when coding mistakes occur, it will make the browser lock up and be completely unusable.  This becomes even worse when the overhead of rendering with threejs is involved.  

<p>
To help you get started, the code stencil also has a "rrt_canvas" directory where you can implement your RRT in 2D worlds with provided routines for visualization and collision.  Because the RRT is invariant across configuration spaces, an RRT developed for the 2D Canvas world should easily port to the N-D threejs world, with minor changes for invoking drawing routines.

<p>

<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-6".  
<p>
(comment end) -->

<h2 id="assignment7">Assignment 7: The best use of robotics? </h2>  
<p>
<b>Due 1:30pm, Wednesday, April 13, 2016</b>
<p>

Scenario: An investor is considering giving you 3 million dollars (cold hard USD cash, figuratively).  This investor has been impressed by work with kineval and other accomplishments while at the University of Michigan.  They are convinced you have the technical ability to make a compelling robot technology... but, they are unsure how this technology could produce something useful.  Your task is to make a convincing pitch for a  robotics project that would yield a high return on investment. 
<!-- (uncomment)
<p>
You will get 2 minutes to make a pitch to develop something useful with robots.  Consider the instructor and your classmates as the people that need to be convinced.  As a guideline, your pitch should address an opportunity (presented by a need or a problem), your planned result (as a system, technology, product, and/or service), and how you will measure successful return on investment.  Return on investment can be viewed as financial profit (wrt. venture capital), good for society (wrt. a government program), creation of new knowledge or capabilities (wrt. a grant for scientific research).  Remember, the purpose is to convince and inspire about what is possible, rather than dive into specifics.
<p>
The last scheduled class period and a little more (Wednesday April 13th, 1:30-4:30pm) will be dedicated to student presentations to pitch ideas on the best use of robotics.  Please email your slides to the instructor before 9am on Monday April 11th with the subject line ("AutoRob asgn7 pitch slides").  OS X Keynote will be used as the sole means of slide presentation, and will be timed and controlled by the instructor.  As such, slide materials can be accepted as Keynote, Powerpoint (no guarantees on conversion), PDF, and common image and video formats (JPG, PNG, MP4, FLV, etc.).
<p>
(end comment) -->
The pitch judged to be the most convincing will get first dibs.
<p>

<p>
<br>
<br>
<h1>Additional Materials</h1>

<h2 id="git_tutorial">Appendix: Git-ing Started with Git</h2>  

<p>
Using version control effectively is an essential skill for both the AutoRob course and, more generally, contributing to advanced projects in robotics research and development.  git is arguably the most widely used version control system at current.  Examples of the many robotics projects using git include: 
<a href="https://github.com/lcm-proj">Lightweight Communications and Marshalling</a>,
<a href="https://github.com/ros">the Robot Operating System</a>,
<a href="https://github.com/RobotWebTools">Robot Web Tools</a>,
<a href="https://github.com/fetchrobotics">Fetch Robotics</a>,
<a href="https://bitbucket.org/nasa_ros_pkg/nasa_r2_simulator">the NASA Robonaut 2</a>, and
<a href="https://github.com/RethinkRobotics">the Rethink Baxter</a>.
To help you use git effectively, the course staff has added the tutorials below for getting started with git.
This is meant to be a starting guide to using git, bash, and Git Bash.  For a more complete list of commands and features of git, you can refer to the following guides: <a href="http://git-scm.com/book/en/v2/Getting-Started-Installing-Git">The Git Pro book</a> or The <a href="http://www.mathworks.com/help/instrument/using-tcpip-server-sockets.html">Basic git command line reference for windows users</a>. 
</p>



<h3>Installing git</h3>

<p>
The AutoRob course assumes git is used from an command line terminal to work with a git hosting service, such as <a href="github.com">GitHub</a> or <a href="bitbucket.com">Bitbucket</a>.  Such terminal environments are readily available in Linux and Mac OSX through their respective terminal programs.  For MS Windows, we are recommending <a href="https://openhatch.org/missions/windows-setup/install-git-bash">Git Bash</a>, although several other viable alternatives exist.  Applications that provide a Graphical User Interface for git are not recommended.  
</p>

<p>
git can be installed on Linux through a common package managment system, based on your distribution, with one of the following commands:
</p>

<pre><code data-language="javascript">
sudo yum install git-all
</code></pre>
<pre><code data-language="javascript">
sudo apt-get install git-all
</code></pre>

<p>
For Mac OSX, git can be installed on its own using the <a href="https://code.google.com/p/git-osx-installer/">Git-OSX-Installer</a> or as part of larger set of <a href="https://en.wikipedia.org/wiki/Xcode">Xcode</a> build tools. 
For MS Windows, we are recommending <a href="https://openhatch.org/missions/windows-setup/install-git-bash">Git Bash</a>, although several other viable alternatives exist.  
</p>

<p>
If you have a command line terminal running, you should see a shell environment that looks something like this (screenshot from Git Bash):
</p>

<center>
<img width=80% src="images/gitbash.png">
</center>

<p>
If you have git installed, you should should be able to enter the "git" command and see the following usage information printed (screenshot from OSX):
</p>

<center>
<img width=80% src="images/git_terminal_osx.png">
</center>

<h3>Cloning your repository</h3>

<p>
The most common thing that you will need to do is pull and push files from and to your git hosting service. Upon opening Git Bash, you will need to go to the location of <b>both</b> your GitHub/Bitbucket repository on the web and your git workspace on your local computer.  Our first main step is to clone your remote repository onto your local computer.  Towards this end, the next step is to open your terminal application and determine your current directory, assuming you will use this directory to create a workspace.  For Linux and OSX, the terminal should start in your home directory, often "/home/username" or "/Users/username".  For Git Bash on Windows, the default home directory location could be the Documents in your user directory, or the general user folder within "C:\Users". 
</p>

<p>
From your current directory, you can use Bash commands to view and modify the contents of directories and files.  You can see a list of the files and folders that can be accessed using ls (list) and change the folder using the command cd (change directory) as shown below. If you believe that the directory has files in addition to folders, but would like a list of just the folders, then the command ls –d */ can be used instead of ls.  Below is a quick summary of relevant Bash commands:
</p>

<p>
<ul>
<li>"ls" prints a listing of files in the current directory
<li>"pwd" prints the location of the current directory in the filesystem
<li>"cd [NameFolder]" moves the terminal to a new directory in the filesystem
<li>"ls [Expression]" prints a listing of files in the current directory matching the given Expression; ls r* prints all files starting with the character 'r'
<li>"mkdir [NameFolder]" creates a folder within the current directory. If the folder name has spaces, then NameFolder will need to be in double quotes.
<li>"rmdir [NameFolder]" removes a specified empty folder. If it is not empty, the folder will not be removed.
<li>"rm –rf [NameFolder]" removes a specified folder and all the contents
<li>"touch [FileName]" creates a single empty text file
<li>"touch [FIleName1.txt] [FileName2.txt]..." creates multiple empty text files
<li>"rm [FileName]" removes a specific file from the current directory
<li>"rm –i <FileName]" confirmation prompt required before removing file from current directory. The file name cannot have spaces.
<li>"rm –v [FileName]" removes the file and reports in console
</ul>
</p>

<p>
You are now ready to clone a copy of your remote repository and populate it with files for AutoRob projects.  It assumed that you have already created a repository on your git hosting service, given the course staff access to this repository, and provided a link of your repository to the course staff.  This repository link (in the form of "https://github.com/user_name/repository_name.git") will now be used to clone a copy of your remote repository onto your local machine using the following git command below.  This command will clone the repository contents to a subdirectory labeled with the name of the repository:
</p>

<pre><code data-language="javascript">
  git clone [repository URL link]
</code></pre>

<p>
This directory should be listed and inspected to ensure it has been cloned with the contents of the repository, matching the remote repository from your git hosting service.  If this is a new repository, it is not problem for this directory to be empty:
</p>

<pre><code data-language="javascript">
  ls [repository_name]
</code></pre>

<p>
You can also check for differences between the files on your computer and the remote repository using git status as shown below.  If you receive the message shown in the example below, then there are no differences. If there are differences, then it will have the number of files which are different highlighted in red. 
</p>

<pre><code data-language="javascript">
$ git status
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working directory clean
</code></pre>

<h3>Important: workspace is not the same as repository</h3>

<p>
You should now have a local copy of your repository with a workspace in a subdirectory.  It is critical to note that your local repository is different than the subdirectory with your current workspace.  Your workspace is not automatically tracked by the version control system and considered ephemeral.  Any changes made to your workspace must be committed back into the local repository to be recognized by the version control system.  Further, any changes committed to your local repository must also be pushed remotely to be recognized by your git hosting service.  Thus, any changes made to your workspace can be lost if not committed and pushed, which will be discussed more in later sections.
</p>

<h3>Populating your repository with project stencil code</h3>

<p>
In a separate directory, clone the kineval-stencil repository to a subdirectory on your local machine:
</p>

<pre><code data-language="javascript">
  cd [home_directory]
  git clone https://github.com/ohseejay/kineval-stencil.git
</code></pre>

<p>
Inspect this directory to ensure it has been cloned with the contents of the repository:
</p>

<pre><code data-language="javascript">
  cd kineval-stencil
  ls
</code></pre>

<p>
and open "home.html" from this directory in a web browser and ensure you see the starting point picture for <a href="#assignment1">Assignment 1</a>.  Then, copy the kineval-stencil files to the directory with your workspace
</p>

<pre><code data-language="javascript">
  cd [home directory]
  cp -r kineval-stencil/* <repository_name>/
</code></pre>

<p>
As these copied files are new to your working repository, they need to be added to the repository to ensure they are tracked for version control.  These files are added with the following commands:
</p>

<pre><code data-language="javascript">
  cd [repository name]
  git add * 
</code></pre>

<p>
Below is a more detailed summary of git commands for adding files from your workspace to your repository:
</p>

<ul>
<li>"git add" adds changed files to the next commit. There are several different options which can follow this command. 
<li>"git add –A: adds all new files and changes to the next commit including deletions
<li>"git add ." adds all new files and changes to the next commit without deletions
<li>"git add –u" adds all changes to the next commit without new files
</ul>

<h3>Commit and push to update your repository</h3>

<p>
Whenever you make any significant changes to your repository, these changes should be committed to your local repository and pushed to your remote repository.  Such changes can involve adding new files or modifying existing files in your local workspace.  For such changes, you will first commit changes from your workspace to your local repository using the git commit command:
</p>

<pre><code data-language="javascript">
git commit -a -m "message describing changes"
</code></pre>

<p>
and then pushing these changes from your local repository to a synced repository on your git hosting service:
</p>

<pre><code data-language="javascript">
git push
</code></pre>

<p>
This commit will occur to the "master" branch of your repository.
</p>

<p>
Note: the change files must be located in the correct repository folder on your local computer and these commands should be performed in the local workspace directory.  Below is a more detailed summary of git commands for adding files from your workspace to your repository:
</p>

<ul>
<li>"git commit" commits files with changes. There are several options that can follow this. The message text is required and is good practice to list changes that you have made. GitHub is good at tracking changes.
<li>"git commit [FileName] -m 'Message'" commits changes to a specific file
<li>"git commit –a “Message'" commits all files changed since last commit
<li>"git commit –a –m “Message'" commits all files changed since last commit but not new files
<li>"git push" pushes the committed changes to remote repository 
</ul>

<p>
Once you have committed and pushed, your local workspace becomes irrelevant as your changes have been stored and tracked remotely.  The local workspace can now be deleted without concern.  This local workspace can also be updated with changes to the remote repository by pulling.
</p>

<h3>Pulling remote changes</h3>

<p>
Changes be made to your remote repository, potentially by other collaborators, without being tracked by your local repository.  This can lead to potential versioning conflicts when committed changes contradict each other.  For the AutoRob course, versioning conflicts should not be a problem because commits to your repository should be yours alone.  That said, one good practice is to ensure your workspace, local repository, and remote repository are synced before making any changes.  A brute force method for doing this is to re-clone your repository each time you begin to make changes.  Another option is to pull remote changes into your local repository and workspace using the git pull command (or git fetch command):
</p>

<pre><code data-language="javascript">
cd [repository_name]
git pull
</code></pre>

<p>
Below is a more detailed summary of git commands for pulling and fetching:
</p>

<ul>
<li>"git pull [RemoteName]" is used for retrieving commits and merging the files to what is already on the computer. This may make changes to the files that are already there; effectively, this is a fetch followed by a merge.  If you need to pull directly from the repository which already exists and has been accessed through the change directory command, then you do not list a [RemoteName]. 
<li>"git fetch <RemoteName>" used for retrieving commits from a repository that does not already exist on the user’s computer. This creates an exact copy of the files to your local repository and not to the workspace. 
</ul>

<!--
Some easy options for controlling previous and current versions of files can be done through the following commands.
git reset -- hard undo everything from last commit
git reset – hard ORIG_HEAD undo last successful merge and following changes
git reset –soft HEAD^ undo most recent commit
git reset HEAD [FileName] remove a file from the next commit
-->

<h3>Branching</h3>

<p>
You will use branching to submit assignments for the AutoRob course.  
Branching is an effective mechanism for enabling changes to a repository to be done in parallel and then merged at a later point.  A branch essentially creates a copy of your repository at a particular version.  Branches are independently tracked by the version controller and can be merged together when requested (which collaboratively results in a "pull request").  The larger story for branching and merging is outside the scope of AutoRob.
</p>

<p>
You are expected to work primarily out of the "master" branch of your repository.  Once you have completed an assignment, you will create a copy of your master branch with the proper assignment label.  This allows you to continue to work on your master branch while a frozen copy of your assignment is graded.
</p>

<p>
The simplest means for branching in this context is to use the branching feature from the webpage of your remote repository.  From GitHub, simply select the master branch from the "Branch: " button and enter the name of the branch to be created.  From Bitbucket, select the "Branches" icon from the left hand toolbar and follow the instructions for branch creation.  If successful, you should see a list of branches that can each be inspected for their respective contents.  Branches can also be deleted from this interface.
</p>

<p>
A branch can also be created from the command line by the following, which will create a copy of the current branch:
</p>

<pre><code data-language="javascript">
git branch [branch_name]
</code></pre>

<p>
You can switch between branches with the following command:
</p>

<pre><code data-language="javascript">
git checkout [branch_name]
</code></pre>

<p>
as well as clone a specific branch from a repository:
</p>

<pre><code data-language="javascript">
git clone -b [branch_name] [repository URL link]
</code></pre>

<p>
Good luck and happy hacking!
</p>

<br>
<br>

<img width=100% src="images/um_fetch.jpg">


        <!-- TYPEKIT -->
        <script type="text/javascript" src="resources/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script type="text/javascript" src="resources/rainbow_github.min.js"></script>
        <script type="text/javascript" src="resources/rainbow_github_generic.js"></script>
<!--
        <script type="text/javascript" src="//use.typekit.net/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/rainbow.min.js"></script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/language/generic.js"></script>
-->

</body>

</html>
