<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>UM EECS 398/567 - Autonomous Robotics</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">

    <!-- Combo with CSSNormalize, CSSGrids-Responsive, CSSForm, CSSTable, CSSList (v3.9.1) -->
    <link rel="stylesheet" href="resources/yahoo_cssbutton-min.css">
    <link rel="stylesheet" href="resources/yahoo_gallerycss-cssform-min.css">
    <link rel="stylesheet" href="resources/yahoo_cssgrids-responsive-min.css">
    <link rel="stylesheet" href="resources/yahoo_gallerycss-csslist-min.css">
    <link rel="stylesheet" href="resources/yahoo_cssnormalize-min.css">
    <link rel="stylesheet" href="resources/yahoo_gallerycss-csstable-min.css">

    <!-- Some custom styles to make things pretty. -->
    <link rel="stylesheet" type="text/css" href="resources/ui.css">

    <!-- RainbowJS Syntax Highlighting - Github Theme. 
         For more themes, go to https://github.com/ccampbell/rainbow/tree/master/themes -->
    <link rel="stylesheet" type="text/css" href="resources/rainbow_github.css">


    <!-- Modify header colors here to customize the look and feel of the site-->
    <style>
        
        .header {
            background: rgb(0, 39, 76);
         }
            .header h1 {
                color: white;
            }
             .header h2 {
                 font-weight:300;
                 margin:0;
                 color: rgb(116, 130, 230);
             }
    </style>

</head>

<body class='yui3-skin-sam'>

    <div id="headerMenu" class="yui3-menu yui3-menu-open yui3-menu-horizontal yui3-menu-fixed">
        <span class="yui3-menu-heading">AutoRob</span>
        <ul>
            <li class="yui3-menu-active"><a href="#schedule">schedule</a></li>
            <li><a href="https://github.com/ohseejay/kineval-stencil-fall16">kineval</a></li>
            <li><a href="#git_tutorial">git</a></li>
            assignments:
            <li><a href="#assignment1">1</a></li>
            <li><a href="#assignment2">2</a></li>
            <li><a href="#assignment3">3</a></li>
            <li><a href="#assignment4">4</a></li>
<!-- unassigned
            <li><a href="#assignment5">5</a></li>
            <li><a href="#assignment6">6</a></li>
            <li><a href="#assignment7">7</a></li>
-->
        </ul>
    </div>
    <div class="header yui3-u-1">

        <h1 class="yui3-u-1">UM EECS 398-001</h1>
        <h2 class="yui3-u">Introduction to Autonomous Robotics</h2>
        <h1 class="yui3-u-1">UM ME/EECS 567</h1>
        <h2 class="yui3-u">Robot Kinematics and Dynamics</h2>
        <br>
        <br>
        <h2 class="yui3-u">Fall 2017</h2>

     </div>
    <div class="content">
<p>
<center>
<img width=100% src="images/um_fetch.jpg">
</center>


<!--
<hr>
<h1> The current version of the AutoRob course website is preliminary.  An updated version of the Fall 2017 site will be available soon.  The descriptions below are unofficial and tentative.</h1>
<hr>
-->

        <h2>Introduction</h2>

<p>
The AutoRob course provide an introduction to core topics in the modeling and control of autonomous robots.  AutoRob has two sections: an undergraduate section offered as Introduction to Autonomous Robotics (EECS 398) and a graduate section offered as Robot Kinematics and Dynamics (ME/EECS 567) with expanded advanced material.  The AutoRob course can be thought of as the foundation to build “brains for robots”. That is, given a robot as a machine with sensing, actuation, and computation, how do we build computational models, algorithms, and program that allow the robot to function autonomously? Such computation involves functions for robots to perceive the world, make decisions towards achieving a given objective, and transforming decided actions into motor commands.  These functions are essential for modern robotics, especially for mobile manipulators such as the pictured <a href="http://fetchrobotics.com/research/">Fetch</a> and <a href="https://www.willowgarage.com/pages/pr2/overview">PR2</a> robots.
</p>

<p>
The AutoRob course focuses on the issues of modeling and control for autonomous robots with an emphasis on manipulation and mobility.  Successful completion of AutoRob will result in code modules for "mobile pick-and-place".  That is, given a robot and perception of the robot's environment, resulting code modules can enable the robot to pick up an object at an arbitrary location and place the object in a new location.
</p>

<!--
Caveats: robot will perform suboptimally based on rrt-planner, no self-collision checking, assume object is graspable and pickable, need grasp planner, no respect for joint motor and angle limits, translate between ROS
-->


<p>
AutoRob projects ground course concepts through implementation in JavaScript/HTML5 supported by the KinEval code stencil (snapshot below from Mozilla Firefox).  These projects will cover graph search path planning (A* algorithm), basic physical simulation (Lagrangian dynamics, numerical integrators), proportional-integral-derivative (PID) control, forward kinematics (3D geometric matrix transforms, matrix stack composition of transforms, axis-angle rotation by quaternions), inverse kinematics, (gradient descent optimization, Jacobians for velocity kinematics), and motion planning (simple collision detection, sample-based motion planning).  Additional topics that could be covered include potential field navigation, Bayesian filtering, Cyclic Coordinate Descent, Monte Carlo localization, and Newton-Euler dynamics.  
</p>

<img width=100% src="images/kineval_fetch.png">

<p>
AutoRob projects will roughly follow conventions and structures from the <a href="http://ros.org">Robot Operating System (ROS)<a> and <a href="https://github.com/RobotWebTools">Robot Web Tools (RWT)</a> software frameworks, as currently used on the Fetch and PR2 robots.  These conventions include the URDF kinematic modeling format, ROS topic structure, and JSON-based messaging.

Kineval uses <a href="http://threejs.org/">threejs</a> for in-browser 3D rendering and <a href="http://numericjs.com">Numeric Javascript</a> for select matrix routines.  Auxiliary code examples and stencils will often use the <a href="http://jsfiddle.net/">jsfiddle</a> development environment.    
</p>

<h3>Related Courses</h3>

<p>
AutoRob is a computing-friendly pathway into robotics, but does not cover the whole of robotics.  The scope of AutoRob is robot modeling and control, which is well-suited as preparation for a Major Design Experience in EECS 467 (Autonomous Robotics Laboratory).  AutoRob provides a computation-focused version of ME 567 (Robot Kinematics and Dynamics).  The common ME 567 is a more in-depth mathematical analysis of dynamics and control with extensive use of Denavit-Hartenberg parameters for kinematics.  AutoRob spends more coverage on path and motion planning with use of quaternions and matrix stacks for kinematics.
</p>

<p>
AutoRob is also a complement to courses covering perception (EECS 568 Mobile Robotics, EECS 442 Computer Vision), robot building (EECS 498 Hands-on Robotics, ME 552 Mechatronics), robot simulation (ME 543 Analytical and Computational Dynamics), controls systems (EECS 460 Control Systems Analysis and Design, EECS 461 Embedded Control Systems), and artificial intelligence (EECS 492 Introduction to Artificial Intelligence), as well as general graduate courses in robotics (ROB 501 Math for Robotics, ROB 550 Robotic Systems Laboratory).  
</p>

<h3>Commitment to equal opportunity</h3>

<p>
As indicated in the <a href="http://www.engin.umich.edu/college/academics/bulletin/rules#generalstandardsofconductforengineeringstudents">General Standards of Conduct for Engineering Students</a>, this course is committed to a policy of equal opportunity for all persons and do not discriminate on the basis of race, color, national origin, age, marital status, sex, sexual orientation, gender identity, gender expression, disability, religion, height, weight, or veteran status. Please feel free to contact the course staff with any problem, concern, or suggestion. We ask that all students treat each other with respect.
</p>

<h3>Accommodations for Students with Disabilities</h3>

<p>
If you believe an accommodation is needed for a disability, please let the course instructor know at your earliest convenience. Some aspects of this course, the assignments, the in-class activities, and the way the course is usually taught may be modified to facilitate your participation and progress. As soon as you make us aware of your needs, the course staff can work with the <a href="http://ssd.umich.edu">Services for Students with Disabilities</a> (SSD, 734-763-3000) office to help us determine appropriate academic accommodations. SSD typically recommends accommodations through a Verified Individualized Services and Accommodations (VISA) form. Any information you provide is private and confidential and will be treated as such. For special accommodations for any academic evaluation (exam, quiz, project), the course staff will need to receive the necessary paperwork issued by the SSD office by <i>September 29, 2017</i>.
</p>

<h3>Student mental health and well being</h3> 

<p>
The University of Michigan is committed to advancing the mental health and
wellbeing of its students. If you or someone you know is feeling
overwhelmed, depressed, and/or in need of support, services are available.
For help, please contact <a href="https://caps.umich.edu/">Counseling and Psychological Services</a> (CAPS) by phone at 734-764-8312, during and after hours, on
weekends and holidays, or through its counselors physically located in
schools on both North and Central Campus. You may also consult <a href="https://www.uhs.umich.edu/mentalhealthsvcs">University Health Service</a> (UHS, 734-764-8320) as well as its <a href="https://www.uhs.umich.edu/aodresources">services for alcohol or drug concerns</a>.
There is also a more comprehensive <a href="http://umich.edu/~mhealth/">listing of mental health resources</a> available on and off campus.
</p>

<h2>Course Staff</h2>

<h3>Instructor</h3>

<p><a href="http://web.eecs.umich.edu/~ocj">Chad Jenkins</a> 
<br>
ocj addrsign umich
<br>
Office: Beyster 3644
<br>
Office Hours: Monday 3-5pm, Tuesday 2-4pm
</p>

<h3>GSI</h3>

<p>Zhen Zeng
<br>
zengzhen addrsign umich
<br>
Office Hours (Beyster 1637 A): Wednesday 3-5pm, Thursday 3-5pm
</p>



<h2>Meeting time/place</h2>
<p>
Monday, Wednesday 1:30-3:00 
<br>DOW 2150
</p>

<h2>Discussion channel</h2>

<p>
<a href="https://autorob.slack.com/messages/general/">AutoRob #general channel</a>
</p>

<p>
Note: General course discussion and administrivia will be addressed in the #general channel.  
Each assignment will have its own discussion channel.
Random items of general interest to the course and larger field of robotics will appear in the #random channel.  
<i>Actively engaging in course discussions is a great way to become a better roboticist.</i>
</p>

<h2>Prerequisites</h2> 

<p>
This course has recommended prerequisites for "Linear Algebra" and "Data Structures and Algorithms", or permission from the instructor.
</p>

<p>
<i>Programming proficiency</i>: EECS 281 or proficiency in data structures and algorithms should provide an adequate programming background for the projects in this course.  Interested students should consult with the course instructor if they have not taken EECS 281 or its equivalent, but have some other strong programming experience.
</p>

<p>
<i>Mathematical proficiency</i>: Math 214, 217, 417, 419 or proficiency in linear algebra should provide an adequate mathematical background for the projects in this course.  Interested students should consult with the course instructor if they have not taken one of the listed courses or their equivalent, but have some other strong background with linear algebra.
</p>

<p>
Recommended optional proficiency: Differential equations, Computer graphics, Computer vision, Artificial Intelligence
</p>

<p>
The instructor will do their best to cover the necessary prerequisite material, but no guarantees.  Linear algebra will be used extensively in relation to 3D geometric transforms and systems of linear equations.  Computer graphics is helpful for under-the-hood understanding of threejs.  Computer vision and AI share common concepts with this course.  Differential equations are used to cover modeling of motion dynamics and inverse kinematics, but not explicitly required.
</p>

<h2>Textbook</h2>

<p>
The AutoRob course is compatible with both the Spong et al. and Corke textbooks (listed below), although only one of these books is needed.  Depending on individual styles of learning, one textbook may be preferrable over the other.  Spong et al. is the listed required textbook for AutoRob (as well as ME 567) and is supplemented with additional handouts.  The Corke textbook provides broader coverage with an emphasis on intuitive explanation.
</p>

<p>
<a href="http://bcs.wiley.com/he-bcs/Books?action=index&itemId=0471649902&bcsId=2888"><b>Robot Modeling and Control</b></a>
<br>
Mark W. Spong, Seth Hutchinson, and M. Vidyasagar
<br>
Wiley, 2005 
<br>
<a href="http://www.amazon.com/Robot-Modeling-Control-Mark-Spong/dp/0471649902">Available at Amazon</a>

<p>
<h3>Alternate textbook</h3>
<p>

<a href="http://www.springer.com/us/book/9783642201431"><b>Robotics, Vision and Control: Fundamental Algorithms in MATLAB</b></a>
<br>
Peter Corke
<br>
Springer, 2011


<p>
<h3>Optional texts</h3>
<p>

<a href="http://shop.oreilly.com/product/9780596517748.do"><b>JavaScript: The Good Parts</b></a>
<br>
Douglas Crockford
<br>
O'Reilly Media / Yahoo Press, 2008

<p>
<a href="http://mitpress.mit.edu/books/principles-robot-motion"><b>Principles of Robot Motion</b></a>
<br>
Howie Choset, Kevin M. Lynch, Seth Hutchinson, George A. Kantor, Wolfram Burgard, Lydia E. Kavraki, and Sebastian Thrun
<br>
MIT Press, 2005


<h2>Projects and Grading</h2>

<p>
The AutoRob course will assign 7 projects (6 programming, 1 oral) and 5 quizzes.  Each project has been decomposed into a collection of features, each of which is worth a specified number of points.  AutoRob project features are graded as “checked” (completed) or “due” (incomplete). Prior to being assigned, upcoming projects will have the status of "pending."  In terms of workload, each project is expected to take approximately 4 hours of work on average (as a rough estimate).  
Each quiz will consist of 4 short questions that will be within the scope of previously graded projects.  In other words, each quiz question should be readily answerable given knowledge from correctly completing projects on time.
</p>

<p>
Individual final grades are assigned based on the sum of points earned from coursework (detailed in subsections below). 
The timing and due dates for course projects and quizzes will be announced on an ongoing basis.  All project work must be checked by the end of classes.
</p>

<h3>EECS 398-001: Introduction to Autonomous Robotics</h3>

<p>
In the undergraduate section, each fully completed project is weighted as 12 points and each correctly answered quiz question is weighted as 1 point.  
Based on this sum of points from coursework, an overall grade for the course is earned as follows: An "A" grade in the course is earned if graded coursework sums to 93 points or above; A "B" grade in the course is earned if graded coursework sums to 83 points or above; a "C" grade in the course is earned if graded coursework sums to 73 points or above.  The instructor reserves the option to assign appropriate course grades with plus or minus modifiers.
</p>

<!--???<a href="https://www.michigandaily.com/content/viewpoint-qwizdom-can-help">pop quiz</a>--> 

<h3>ME/EECS 567: Robot Kinematics and Dynamics</h3>

<p>
In the graduate section, each fully completed project is weighted as 18 points, each correctly answered quiz question is weighted as 1 point.  Students in the EECS 598-009 have the opportunity to earn 4 additional points through an advanced extension of a course project.  Examples of advanced extensions include implementation of RK4 numerical integration for a double pendulum, inverse kinematics by Cyclic Coordinate Descent, one additional motion planning algorithm, point cloud segmentation, and a review of a current research publication in robotics.
Based on this sum of points from coursework, an overall grade for the course is earned as follows: An "A" grade in the course is earned if graded coursework sums to 135 points or above; A "B" grade in the course is earned if graded coursework sums to 120 points or above; a "C" grade in the course is earned if graded coursework sums to 105 points or above.  The instructor reserves the option to assign appropriate course grades with plus or minus modifiers.
</p>

<h3 id="project_rubric">Project Rubric (tenative and subject to change)</h3>

<p>
The following project features are planned for AutoRob this semester.  Students enrolled in ME/EECS 567 will complete all features.  Students in the undergraduate section are not expected to implement features for the graduate section.
</p>

<table cellpadding=5 border=0  width="100%">
<col align="center">
<col align="center">
<col align="center">
<tr bgcolor="#aaaaaa">     
        <th style="width:100px"><b><center>Points</center></b></th> 
        <th style="width:100px"><b><center>Sections</center></b></th>
        <th style="width:600px"><b><center>Feature</center></b></th>
</tr>

<tr bgcolor="#dddddd">     
<td></td><td></td><td>Assignment 1: 2D Path Planning</td>
</tr>

<tr><td>4</td><td>All</td><td> Heap implementation</td></tr>
<tr><td>8</td><td>All</td><td> A-star search</td></tr>
<tr><td>2</td><td>567</td><td> BFS</td></tr>
<tr><td>2</td><td>567</td><td> DFS</td></tr>
<tr><td>2</td><td>567</td><td> Greedy best-first</td></tr>

<tr bgcolor="#dddddd">     
<td></td><td></td><td>Assignment 2: Pendularm</td>
</tr>

<tr><td>4</td><td>All</td><td> Euler integrator</td></tr>
<tr><td>4</td><td>All</td><td> Velocity Verlet integrator</td></tr>
<tr><td>4</td><td>All</td><td> PID control</td></tr>
<tr><td>1</td><td>567</td><td> Verlet integrator</td></tr>
<tr><td>2</td><td>567</td><td> RK4 integrator</td></tr>
<tr><td>3</td><td>567</td><td> Double pendulum</td></tr>

<tr bgcolor="#dddddd">     
<td></td><td></td><td>Assignment 3: Forward Kinematics</td>
</tr>

<tr><td>2</td><td>All</td><td> Core matrix routines</td></tr>
<tr><td>8</td><td>All</td><td> FK transforms</td></tr>
<tr><td>2</td><td>All</td><td> Joint selection/rendering</td></tr>
<tr><td>2</td><td>567</td><td> Base offset transform</td></tr>
<tr><td>4</td><td>567</td><td> Fetch DH table</td></tr>

<tr bgcolor="#dddddd">     
<td></td><td></td><td>Assignment 4: Dance Controller</td>
</tr>

<tr><td>6</td><td>All</td><td> Quaternion joint rotation</td></tr>
<tr><td>2</td><td>All</td><td> Interactive base control</td></tr>
<tr><td>2</td><td>All</td><td> Pose setpoint controller</td></tr>
<tr><td>2</td><td>All</td><td> Dance FSM</td></tr>
<tr><td>2</td><td>567</td><td> Joint limits</td></tr>
<tr><td>2</td><td>567</td><td> Prismatic joints</td></tr>
<tr><td>2</td><td>567</td><td> Fetch rosbridge interface</td></tr>

<tr bgcolor="#dddddd">     
<td></td><td></td><td>Assignment 5: Inverse Kinematics</td>
</tr>

<tr><td>6</td><td>All</td><td> Manipulator Jacobian</td></tr>
<tr><td>3</td><td>All</td><td> Gradient descent with Jacobian transpose</td></tr>
<tr><td>3</td><td>All</td><td> Jacobian pseudoinverse</td></tr>
<tr><td>6</td><td>567</td><td> Euler angle conversion</td></tr>
<!--<tr><td>!</td><td> SVD</td></tr> -->

<tr bgcolor="#dddddd">     
<td></td><td></td><td>Assignment 6: Motion Planning</td>
</tr>

<tr><td>4</td><td>All</td><td> Collision detection</td></tr>
<tr><td>2</td><td>All</td><td> 2D RRT-Connect</td></tr>
<tr><td>6</td><td>All</td><td> Configuration space RRT-Connect</td></tr>
<tr><td>6</td><td>567</td><td> RRT-Star</td></tr>
</table>






<h3>Project Submission and Regrading</h3>

<p>
Git repositories will be used for project implementation, version control, and submission. The implementation of an individual project is submitted through an update to the <i>master</i> branch of your designated repository.  Updates to the master branch must be committed and pushed prior to the due date for each assignment for any consideration of full credit. Your implementation will be checked out and executed by the course staff. Through your repository, you will be notified by the course staff whether your implementation of assignment features is sufficient to receive credit. 
</p>

<!-- update this advice
<p>
Note: you should work primarily from your "master" branch, as this represents the current state of your progress .  Branches for assignment submissions are meant to remain as snapshots for grading.  Such branches allow grading of and instructional feedback on your submitted code while still working with and modifying your master branch.  In addition, errors in a submitted branch can be updated without disturbing your progress on a project in the master branch (or another project branch).
<del>If a feature is insufficient for receiving a check, you are allowed one regrade (per assignment) with 2 weeks of notification. If deemed necessary, the course staff may require an interactive demonstration of your implementation and/or a web-based written report.</del>
</p>
-->

<h3>Late Policy</h3>
<p>
Do not submit assignments late.  The course staff reserves the right to not grade late submissions. The course instructor reserves the right to decline to grade late submissions and adjust partial credit on regraded assignments.  
If granted by the course instructor, late submissions can be graded for partial credit, with a guideline as follows.  Submissions pushed within two weeks past the project deadline will be graded for 80% credit.   Submissions pushed within four weeks of the project deadline will be graded for 60% credit.  Submissions pushed at any time before the semester project submission deadline (December 15, 2017) will be considered for 50% credit.  The course instructor reserves the right to decline to grade late submissions and adjust partial credit on regraded assignments.
</p>

<h3>Regrading Policy</h3>
<p>
The regrading policy allows for submission and regrading of projects up through the final grading of projects, which will be December 15 for the Fall 2017 Semester.  This regrading policy will grant full credit for project submissions pushed to your repository before the corresponding project deadline.  If a feature of graded project is returned as not completed (or "DUE"), your code can updated for consideration at 80% credit.  This code update must be pushed to your repository within two weeks from when the originally graded project was returned.  Regrades of projects updated beyond this two week window can receive at most 60% credit.  
</p>

<h3>Final Grading</h3>

<p>
All grading will be finalized on December 15, 2017.  Regrading of specific assignments can be done upon request during office hours.  No regrading will be done after grades are finalized.

<h3>Repositories</h3>

<p>
You are expected to provide a <b>private</b> git repository for your work in this course with the course instructor added as a read/write collaborator.  If needed, the course staff can assist in the setup of an online git repository through providers such as <a href="https://github.com/">github</a> or <a href="https://bitbucket.org/">bitbucket</a>, or internally through the EECS <a href="https://gitlab.eecs.umich.edu">gitlab</a> server.

<!--
Your repository is expected to have the following subdirectories, at a minimum, as well as the file "grading.txt" with your updated course grading status:
</p>

<p class="indented">
<b>p_project</b>: containing implementation and build and execution instructions for the preparatory project<br>
<b>reviews</b>: containing reviews of assigned papers in plain text format<br> 
<b>presentation</b>: containing paper presentation slides in PDF format<br>
<b>proposal</b>: containing final project proposal in plain text format<br>
<b>f_project</b>: containing final project implementation and slides (in PDF format) <br>
</p> 
-->

<p>
There are many different tutorials for learning how to use git repositories.  The AutoRob course site has its own basic <a href="#git_tutorial">quick start tutorial</a>.  The EECS gitlab server has a basic <a href="http://gitlab.eecs.umich.edu/help/gitlab-basics/README.md">quick start tutorial</a>.  The <a href="http://www.git-scm.com/book/en/v2">Pro Git book</a> provides an in-depth introduction to git and version control.  As different people often learn through different styles, the <a href="http://www-cs-students.stanford.edu/~blynn/gitmagic/">Git Magic tutorial</a> has also proved quite useful when a different perspective is needed.  <a href="http://rogerdudler.github.io/git-guide/">git: the simple guide</a> has often been a great and accessible quick start resource. 
</p>

<p>
We expect students to use these repositories for collaborative development as well as project submission. It is the responsibility of each student group to ensure their repository adheres to the Collaboration Policy and submission standards for each assignment. Submission standards and examples will be described for each assignment as needed.
</p>


<h3>Collaboration Policy</h3>
<p>
 This policy covers all course material and assignments unless otherwise stated. Course material, concepts, and documentation may be discussed with anyone.  Assignments may be discussed with the other students at the conceptual level.  Discussions may make use of a whiteboard or paper.  Discussions with others (or people outside of your assigned group) cannot include writing or debugging code on a computer or collaborative analysis of source code that is not your own. You may take notes away from these discussions, provided these notes do not include any source code.
</p>

<p>
The code for your implementation may not be shown to anyone outside of your group, including granting access to repositories or careless lack of protection. You do not need to hide the screen from anyone, but you should not attempt to show anyone your code. When you are done using any robot device such that another group may use it, you must remove all code you have put onto the device. You may not share your code with others outside of your group. At any time, you may show others the implemented program running on a device or simulator, but you may not discuss specific debugging details about your code while doing so.
</p>

<p>
This policy applies not only applies to collaboration during the current semester, but also any past or future instantiations of this course.  Although course concepts are intended for general use, your implementation for this course must remain private after the completion of the course.  It is expressly prohibited to share any code previously written and graded for this course with students currently enrolled in this course.  Similarly, it is expressly prohibited for any students currently enrolled in this course to refer to any code previously written and graded for this course.
</p>

<p>
To acknowledge compliance with this collaboration policy, include a file named "honor.txt" in the main directory of your repository with the following text: "I have neither given nor received unauthorized aid on this course project implementation, nor have I concealed any violations of the Honor Code."  This text will be considered updated with the current date and time of each commit to your repository.  Repository commits that do not include this honor file will not be graded as the discretion of the course advisor.
</p>

<p>
Should you fail to abide by this policy, you will receive no credit for this course.  The University of Michigan reserves the right to pursue any means necessary to ensure compliance. This includes, but is not limited to prosecution through The College of Engineering’s Honor Council, which can result in your suspension or expulsion from the University of Michigan.  Please refer to the <a href ="http://ossa.engin.umich.edu/honor-council/">Engineering Honor Council</a> for additional information.
</p>

<h2 id="schedule">Course Schedule (tentative and subject to change)</h2>

Note: Assignment descriptions will have updated assignment due dates.  Assignment due dates listed in the schedule are merely a guide.

<table cellpadding=5 border=0  width="100%">
<tr bgcolor="#dddddd">     
        <th style="width:40px"><b><center>Date</center></b></th> 
        <th style="width:500px"><b><center>Topic</center></b></th>
        <th style="width:150px"><b><center>Reading</center></b></th>
        <th style="width:200px"><b><center>Project</center></b></th>
</tr>

<tr>
    <td><b>Sep 6</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_01_initialization.pdf">
         Initialization</a>: 
         Course overview, Robotics roadmap, Path planning quick start<br>
    </td>
    <td>Spong Ch.1<hr>Corke Ch.1</td> 
    <td>Out: <a href="#assignment1">Path Planning</a></td> 
</tr>

<tr>
    <td></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_00_robot_what_is.pdf">
         What is a robot?</a>: 
         Brief history and definitions for robotics<br>
    </td>
    <td></td> 
    <td></td> 
</tr>


<!--
<tr>
    <td><b>Jan 8</b></td>
    <td>
         <a href="slides will go here">JavaScript and git tutorial</a> <br>
    </td>
    <td>Crockford</td> 
    <td></td> 
</tr>
-->

<tr bgcolor="#dddddd">     
<td></td><td>Week 2</td><td></td><td></td>
</tr>

<tr>
    <td><b>Sep 11</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_02_graph_search.pdf">
         Path Planning</a>: DFS, BFS, A-star, Greedy best first<br>
    </td>
    <td>
         <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">Wikipedia</a>
    </td> 
    <td></td> 
</tr>

<tr>
    <td></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_02_jsh5_git.pdf">
         JavaScript and git tutorial</a>: Heap sort example<br>
    </td>
    <td>Crockford,
    <a href="examples/hello.html">hello.html</a>,
    <a href="examples/hello_anim.html">hello_anim</a>,
    <a href="examples/hello_anim_text.html">hello_anim_text</a> 
    </td> 
    <td></td> 
</tr>

<!--
<tr>
    <td><b>Sep 13</b></td>
    <td>
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_00_robot_what_is.pdf">
         What is a robot?</a><br>
    </td>
    <td>Spong Ch 1<hr>Corke Ch 1</td> 
    <td></td> 
</tr>
-->

<tr>
    <td><b>Sep 13</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_03_dynamics_pendulum.pdf">
         Pendulum Simulation and Numerical Integration</a>:  Lagrangian equation(s) of motion, Initial value problem, Explicit integrators:  Euler, Verlet, and Runge-Kutta 4<br>
    </td>
    <td>
        <a href="https://en.wikipedia.org/wiki/Euler_method">Handout: 1</a>,
        <a href="https://en.wikipedia.org/wiki/Verlet_integration">2</a>,
        <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#The_Runge.E2.80.93Kutta_method">3</a>; <br>
        Witkin&Baraff 1998:
        <a href="https://www.cs.cmu.edu/~baraff/sigcourse/notesd1.pdf">Dynamics</a>,
        <a href="https://www.cs.cmu.edu/~baraff/sigcourse/notesb.pdf">Integrators</a>
    </td> 
    <td></td> 
</tr>


<!--
<tr>
    <td><b>Sep 19</b></td>
    <td>
         <a href="">TBD</a>: TBD <br>
         <a href="http://www.history.com/topics/black-history/martin-luther-king-jr">Martin Luther King Jr. Day</a>: Help broaden participation in computing and robotics <br>
    </td>
    <td></td> 
    <td></td> 
</tr>
-->

<tr bgcolor="#dddddd">     
<td></td><td>Week 3</td><td></td><td></td>
</tr>



<tr>
    <td><b>Sep 18</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_04_control_pid.pdf">
         Motion Control</a>: Cartesian vs. generalized coordinates, open-loop vs. closed-loop control, PID control; Rigid body dynamics<br>
    </td>
    <td>Spong 6.3<hr><a href="http://www.cds.caltech.edu/~murray/courses/cds101/fa02/caltech/astrom-ch6.pdf">Handout</a></td> 
    <td>Due: Path Planning
    <br>Out: <a href="#assignment2">Pendularm</a>
    </td> 
</tr>


<tr>
    <td><b>Sep 20</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_05_linear_refresh.pdf">
         Linear Algebra Refresher</a>: Systems of linear equations, vector spaces and operations, matrix operations, least squares approximations<br>
         <!-- FUTURE: move FK here -->
    </td>
    <td>Spong A-B<hr>Corke D</td> 
    <td></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 4</td><td></td><td></td>
</tr>

<tr>
    <td><b>Sep 25</b></td>
    <td><b> No class</b> - <a href="http://www.iros2017.org/">IROS 2017</a></td>
        
</tr>


<tr>
    <td><b>Sep 27</b></td>
    <td>
         Quiz 1
    </td>
    <td></td> 
    <td></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 5</td><td></td><td></td>
</tr>


<tr>
    <td><b>Oct 2</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_06_fk_matrixstack.pdf">
         Forward Kinematics</a>: Kinematic chains, URDF, homogeneous transforms, matrix stack traversal, D-H convention<br>
       
         <!-- FUTURE: cover Newton-Euler here -->
    </td>
    <td>Spong 3.1-2<hr>Corke 7.1-2</td> 
    <td></td> 
</tr>

<tr>
    <td><b>Oct 4</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_07_fk_quaternions.pdf">
         Axis-angle Rotation and Quaternions</a>: Motors, Euler angles, gimbal lock, Rodrigues rotation, rotation in complex spaces
    </td>
    <td>
        <a href="https://en.wikipedia.org/wiki/Gimbal_lock">Handout 1</a>, 
        <a href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">2</a>
        <hr>
        Corke 2.2-3
    </td> 
    <td>Due: Pendularm<br>Out: <a href="#assignment3">Forward Kinematics</a></td> 
</tr>


<tr bgcolor="#dddddd">     
<td></td><td>Week 6</td><td></td><td></td>
</tr>

<tr>
    <td><b>Oct 9</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_08_fsm_subsumption.pdf">
         Reactive Controllers</a>: Reactive and Deliberative Decision Making, Finite State Machines, Subsumption Architecture<br>
    </td>
    <td></td> 
    <td></td> 
</tr>



<tr>
    <td><b>Oct 11</b></td>
    <td>
         Quiz 2
    </td>
    <td><a href="https://scratch.mit.edu/projects/10607750/">IK robot game</a></td> 
    <td></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 7</td><td></td><td></td>

</tr>


<tr>
    <td><b>Oct 16</b></td>
    <td><b> No class</b> - Fall Study Break</td>
        
</tr>

<!--
<tr>
    <td><b>Oct 18</b></td>
    <td>
         ROS/rosbridge tutorial session
    </td>
    <td>
         <a href="http://ohseejay.org/papers/rctoris_iros2015.pdf">Toris 2015</a>
    </td> 
    <td>Due: Forward Kinematics<br>Out: <a href="#assignment4">Dance Contest</a></td> 
-->

<tr>
    <td><b>Oct 18</b></td>
    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_10_ik_closedform.pdf">
         Inverse Kinematics 1 - Closed-form</a>: Joint vs. Endeffector control, Planar 2-link arm, Closed form solutions, Cyclic Coordinate Descent<br>
    </td>
    <td>Spong 3.3<hr>Corke 7.3</td> 
    <td>Due: Forward Kinematics<br>Out: <a href="#assignment4">Dance Contest</a></td> 
</tr>


<tr>
<tr bgcolor="#dddddd">     
<td></td><td>Week 8</td><td></td><td></td>

</tr>

<tr>
    <td><b>Oct 23</b></td>

    <td>
         <!-- 
         -->
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_11_ik_jacobian.pdf">
         Inverse Kinematics 2 - Iterative</a>: Gradient descent, Manipulator Jacobian, Jacobian transpose, pseudoinverse
    </td>
    <td>Spong Ch. 4 <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=86079">Wang, Chen 1991</a>,<a href="http://math.ucsd.edu/~sbuss/ResearchWeb/ikmethods/iksurvey.pdf">Buss 2009</a><hr>Corke Ch. 8</td> 
    <td></td> 
</tr>


<tr>
    <td><b>Oct 25</b></td>

    <td>
         ROS/rosbridge tutorial session
    </td>
    <td>
         <a href="http://ohseejay.org/papers/rctoris_iros2015.pdf">Toris 2015</a>
    </td> 
    <td></td> 
</tr>

<!--
<tr>
    <td><b>Oct 24</b></td>
    <td> 
        Extended Office Hours 
    </td> 
    <td>
    Corke Ch. 5
    </td> 
<tr>

<tr>
    <td><b>Oct 26</b></td>
    <td>
         398-002: Extended office hours  <hr> 598-010: rosbridge/Fetch lab session
    </td>
    <td></td> 
    <td></td> 
<tr>
-->

<!--
<tr bgcolor="#dddddd">     
<td></td><td>Week 9: Spring Break</td><td></td><td></td>

</tr>

<tr>
    <td> </td>
    <td><b>Feb 29 - Mar 4</b></td>
    <td> </td>
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 10</td><td></td><td></td>
-->

<tr bgcolor="#dddddd">     
<td></td><td>Week 9</td><td></td><td></td>
</tr>


<tr>
    <td><b>Oct 30</b></td>
    <td> 
         Quiz 3</a> 
    </td> 
    <td>
    </td> 
    <td>Due: Dance Contest <br>Out: <a href="#assignment5">Inverse Kinematics</a></td>
<tr>

<tr>
    <td><b>Nov 1</b></td>
    <td> 
         <!-- 
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_12_bugs.pdf">
         -->
         Bug Algorithms</a>: Reaction vs. Deliberation, Bug[0-2], Tangent Bug</a> 
    </td> 
    <td>
    Corke Ch. 5
    </td>
    <td></td> 
<tr>



<!--
<tr>
    <td><b>Mar 9</b></td>
    <td>398-002: Quiz 2 <hr>598-010: Newton-Euler recursion

</td>
    <td>
    </td> 
<tr>
-->


<tr bgcolor="#dddddd">     
<td></td><td>Week 10</td><td></td><td></td>
</tr>

<tr>
    <td><b>Nov 6</b></td>
    <td>
         <!-- 
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_13_graph_search.pdf">
         -->
         Planning Revisited</a>: graph search revisited, Potential fields, Wavefront planning</a>
    </td>
    <td>Spong Ch. 5 </td> 
    <td></td> 
<tr>


<tr>
    <td><b>Nov 8</b></td>
    <td>
         <!-- 
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_14_configuration_spaces.pdf">
         -->
         Configuration Spaces</a>: Workspaces vs. Configuration spaces, Minkowski sum</a>
    </td>
    <td></td> 
<tr>

<!--
<tr bgcolor="#dddddd">     
<td></td><td>Week 12: No class - off-site meeting</td><td></td><td></td>

</tr>
<tr>
    <td></td>
    <td><b>Mar 21-23</b></td>
    <td></td>
    <td></a></td> 
<tr>
-->

<tr bgcolor="#dddddd">     
<td></td><td>Week 12</td><td></td><td></td>

</tr>

<tr>
    <td><b>Nov 13</b></td>
    <td>
         <!-- 
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_15_roadmaps_rrt_wavefront.pdf ">
         -->
         Motion Planning</a>: Probabilistic roadmaps, RRT-based motion planning, potential fields, wavefront planning
    </td>
    <td><a href="https://personalrobotics.ri.cmu.edu/files/courses/papers/Kuffner00-rrtconnect.pdf">Kuffner, LaValle 1999</a></td> 
<tr>

<tr>
    <td><b>Nov 15</b></td>
    <td>
         <!-- 
         <a href="http://web.eecs.umich.edu/~ocj/courses/autorob/autorob_16_collision_detection.pdf">
         -->
         Collision Detection</a>: Axis-Aligned Bounding Boxes, Separating Axis Theorem 
    </td>
    <td><a href="https://wwwx.cs.unc.edu/~walk/papers/gottscha/sig96.pdf">Gottschalk et al. 1996</a></td> 
    <td>Due: Inverse Kinematics<br> Out: <a href="#assignment6">Motion Planning</a></td> 
<tr>


<!--
<tr bgcolor="#dddddd">     
<td></td><td>Week 13: <a href="http://www.nationalroboticsweek.org/">National Robotics Week</a></td><td></td><td></td>
</tr>
-->
<tr bgcolor="#dddddd">     
<td></td><td>Week 13</td><td></td><td></td>
</tr>

<tr>
    <td><b>Nov 20</b></td>
    <td>
         Quiz 4
    </td>
    <td></td> 
    <td></td> 
</tr>

<tr>
    <td><b>Nov 22 </b></td>
    <td>
        <b> No class</b> - Thanksgiving Recess
    </td>
    <td></td> 
    <td></td> 
<tr>





<!--
<tr>
    <td><b>Apr 5</b></td>
    <td>
         Attend <a href="http://www.mirobotics.org/">Michigan Robotics Day</a>
    </td>
    <td></td> 
<tr>
-->

<tr bgcolor="#dddddd">     
<td></td><td>Week 14</td><td></td><td></td>
</tr>

<tr>
    <td><b>Nov 27</b></td>
    <td>
         <!--
         <a href="slides will go here">
         -->
         Robot Perception Overview</a>: Bayes rule, Bayesian filtering, Monte Carlo Localization, Factor Graphs, SGD-SLAM, Scene estimation
    </td>
    <td><a href="http://www.cc.gatech.edu/~dellaert/pub/Dellaert99icra.pdf">Dellaert 1999</a><br>
    <a href="https://april.eecs.umich.edu/pdfs/olson2006icra.pdf">Olson 2006</a><br>
    <a href="http://ohseejay.org/papers/zsui_iros2015.pdf">Sui 2015</a></td> 
<tr>

<tr>
    <td><b>Nov 29</b></td>
    <td>
         <!--
         <a href="slides will go here">
         -->
         3D Point Cloud Segmentation</a>: Robot Middleware, ROS, <i>rosbridge</i>, Point Clouds, Principal Components Analysis, Connected Components
    </td>
    <td>
        <a href="http://arxiv.org/pdf/1404.1100.pdf">PCA</a><br>
<a href="http://www.willowgarage.com/sites/default/files/Rusu08RAS-Semantic.pdf">Rusu 2008 (Sec 4.2)</a> <br>
    </td> 
    <td></td> 
</tr>

<tr bgcolor="#dddddd">     
<td></td><td>Week 15</td><td></td><td></td>
</tr>

<tr>
    <td><b>Dec 4</b></td>
    <td>Extended office hours</td>
    <td></td>
    <td></td>
<tr>

<tr>
    <td><b>Dec 6</b></td>
    <td>Quiz 5</td>
    <td></td>
    <td>Due: Motion Planning</td> 
<tr>


<tr bgcolor="#dddddd">     
<td></td><td>Week 16</td><td></td><td></td>

</tr>

<tr>
    <td><b>Dec 11</b></td>
    <td>Due: Best Use of Robotics</td>
<tr>

<tr>
    <td><b>Dec 15</b></td>
    <td>Grading finalized</td> 
<tr>

<!--

-->






</table>


<p>

Slides from this course borrow from and are indebted to many sources from around the web.  These sources include a number of excellent robotics courses at various universities.

<!--
<ul>
<li><a href="http://www-clmc.usc.edu/teaching/introductiontorobotics">USC CS 545: Introduction to Robotics</a></li>
<li><a href="https://cirl.lcsr.jhu.edu/SensorBasedRobotics/">JHU 600.336 - Algorithms for Sensor-Based Robotics</a></li>
</ul>
-->

<h2 id="assignment1">Assignment 1: Path Planning</h2>  
<p>
<b>Due 11:59pm, Thursday, September 21, 2017</b>
</p>


<!--
The project description for this assignment will be posted shortly.
-->



<p>
The objective of the first assignment is to implement a collision-free path planner in JavaScript/HTML5.  Path planning is used to allow robots to autonomously navigate in environments from previously constructed maps, which can be estimated through <a href="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping">simultaneous localization and mapping</a>.  For this assignment, you will implement the A-star graph search algorithm for generating the shortest path from a start to a goal location in an arbitrary 2D world.  This A-star implementation will consider locations in a uniformly space grid.  You will implement a heap data structure as a priority queue for visiting these locations.
</p>

<p>
If properly implemented, the A-star algorithm should produce the following path (or path of similar length) using the provided code stencil:
</p>

<center>
<img width=600 src="images/pathplan_narrow2_complete.png">
</center>

<!-- 
<!-- (uncomment marker begin)
-->

<h3>Cloning the Stencil Repository</h3>

<p>
The first step for completing this project (and all projects for AutoRob) is to clone the <a href="https://github.com/ohseejay/kineval-stencil-fall16">KinEval stencil repository Fall 2016</a>.  The appended git quick start below is provided those unfamiliar with git to perform this clone operation, as well as commiting and pushing updates for project submission.  <b>IMPORTANT</b>: the stencil repository should be cloned and <b>not forked</b>.
</p>

<p>
Throughout the KinEval code stencil, there are markers with the string "STENCIL" for code that needs to be completed for course projects.
</p>

<h3>Heap Sort Tutorial</h3>

<p>
For those new to JavaScript/HTML5, the recommended starting point is to complete the heap sort implementation in the "tutorial_heapsort" subdirectory of the stencil repository.  In this directory, a code stencil in JavaScript/HTML5 is provided in two files: "heapsort.html" and "heap.js".  Comments are provided throughout these files to describe the structure of JavaScript/HTML5 and its programmatic features.  In addition, there are other tutorial-by-example files in the "tutorial_js" directory.  Any of these files can be run by simply opening them in a web browser.
</p>

<p>
Opening "heapsort.html" will show the result of running the incomplete heap sort implementation provided by the code stencil:

</p>

<center>
<img width=600 src="images/heapsort_initial.png">
</center>

<p>
To complete the heap sort implementation, complete the heap implementation in heap.js at the locations marked "STENCIL".  In addition, the inclusion of heap.js in the execution of the heap sort will require modification of heapsort.html.
</p>

<p>
A successful heap sort implementation will show the following result for a randomly generated set of numbers:
</p>

<center>
<img width=600 src="images/heapsort_complete.png">
</center>

<h3>Graph Search Stencil</h3>

<p>
For the path planning implementation, a JavaScript/HTML5 code stencil has been provided in the file "search_canvas.html" within the "project_pathplan" subdirectory.  Opening this file in a browser should display an empty 2D world displayed in an <a href="http://www.w3schools.com/html/html5_canvas.asp">HTML5 canvas</a> element.   
</p>

<center>
<img width=600 src="images/pathplan_narrow2_initial.png">
</center>

<p>
There are five planning scenes that have been provided within this code stencil: "empty", "misc", "narrow1", "narrow2", and "three_sections".  The choice of planning_scene can be specified from the URL given to the browser, described in the usage in the file.  For example, the URL "search_canvas.html?planning_scene=narrow2" will bring up the "narrow2" planning world.  Other execution parameters, such as start and goal location, can also be specified through the document URL.
</p>

<p>
This code stencil is implemented to perform graph search iterations interactively in the browser.  The core of the search implementation is performed by the function iterateGraphSearch().  This function performs a graph search iteration for a single location in the A-star execution.  The browser implementation cannot use a while loop over search iterations, as in the common A-star implementation.  Such a while loop would keep control within the search function, and cause the browser to become non-responsive.    Instead, the iterateGraphSearch() gives control back to the main animate() function, which is responsible for updating the display and user interaction. 
</p>

<p>
Within the code stencil, you will complete the functions initSearchGraph() and iterateGraphSearch() as well as add functions for heap operations.  Locations in "search_canvas.html" where code should be added are labeled with the "STENCIL" string.  In initSearchGraph() creates a 2D array over locations to be searched.  Each element of this array contains various information computed by the search algorithm for a particular location.  iterateGraphSearch() should use three of the provided functions to perform a search iteration.  testCollision() returns a boolean of whether a given 2D location, as a two-element vector, is in collision with the planning scene.  draw_2D_configuration() draws a square at a given location in the planning world to indicate that location has been explored.  Once the search is complete, drawHighlightedPathGraph() will render the path produced by the search algorithm between a given location and the start location.  The global variable search_iterate should be set to false to end animation loop.
</p>

<h3> Graduate Section Requirement</h3>

<p>
In addition to the A-star algorithm, students in the graduate section of AutoRob must additionally implement path planning by Depth-first search, Breadth-first search, and Greedy best-first search.  An additional report, as file "report.html", is required that: 1) shows results from executing every search algorithm with every planning world for various start and goal configurations and 2) synthesizes these results into coherent findings about these experiments.
</p>

<h4> Advanced Extensions </h4>

<p>
Advanced extensions can be submitted anytime before the final grading is complete.  Concepts for several of these extensions will not be covered until later in the semester.
</p>

<p>
Of the 4 possible advanced extension points, two additional points for this assignment can be earned by implementing the Bug0, Bug1, Bug2, and TangentBug navigation algorithms.  This bug algorithm implementation should be contained within the file "search_canvas.html" under the "project_pathplan" directory.
</p>

<p>
Of the 4 possible advanced extension points, two additional points for this assignment can be earned by implementing navigation by potential fields and navigation using the Wavefront algorithm.  This potential-based navigation implementation should be contained within the file "search_canvas.html" under the "project_pathplan" directory.
</p>


<p>
Of the 4 possible advanced extension points, one additional point for this assignment can be earned by implementing a navigation algorithm using a probabilistic roadmap.  This roadmap algorithm implementation should be contained within the file "search_canvas.html" under the "project_pathplan" directory.
</p>

<p>
Of the 4 possible advanced extension points, one additional point for this assignment can be earned by implementing costmap functionality using morphological operators.  Based on the computed costmap, the navigation routine would provide path cost in addition path length for a successful search.
</p>


<h3>Project Submission</h3>

<p>
For turning in your assignment, ensure your completed project code has been committed and pushed to the <i>master</i> branch of your repository.  
</p>


<!--
For turning in your assignment, create a branch in your repository labeled "Assignment-1".  <b>NOTE: spelling matters!</b>  More specifically, ensure your completed project code has been committed and pushed to the master branch of your repository.  At this point, create an Assignment-1 branch from the master branch.  The "Assignment-1" branch is essentially a tag and should not be merged back into the master.  You should continue work from the master branch, including committing and pushing updates, while the Assignment-1 branch is being graded.
-->
</p>

<p>
To ensure proper submission of your assignments, please do the following:
</p>

<p>
<ul>
<li><p>confirm with the course instructor (ocj addrsign umich) with your name, email address, and pointer to your repository,</p> </li>
<li><p>ensure the instructor (id:ohseejay) has push/admin access to your repository, which can be confirmed/addressed through email or office hours (or by seeing that the instructor has committed the file "grading.txt")</p></li>
</ul>
</p>

<p>
You are encouraged to update your repository often using branching.  The <i>master</i> branch should be used for the working (or stable) version of your code.   For development, you can create an <i>Assignment-1</i> branch can be created for your work on this project as it in development and experimentation.  Similarly, an <i>Assignment-2</i> branch can be created for the next project as it develops.  Once you complete an assignment, the code from this branch can then be merged into the <i>master</i> branch for grading.  This configuration allows your work to be continually updated and build upon such that versions are tracked and interruptions due to grading are minimized.
</p>
<!--
(uncomment end) -->


<!--
<h2 id="assignment1">Assignment 1: Getting Started (Warm up)</h2>  
<p>
<b>Due 1pm, Wednesday, January 20, 2016</b>
</p>
<p>
In this assignment, you should clone the <a href="https://github.com/ohseejay/kineval-stencil">kineval_stencil</a> repository into your working repository for the course.  kineval_stencil contains a code template for this assignment as well as all projects in the course.  If you open "home.html" in this repository, you should see the jittering disconnected pieces of a robot (described in "robots/mr2.js"), similar to the snapshot below.  This initial mode is the "starting point" state of the stencil to help build familiarity with JavaScript/HTML5 and KinEval.
</p>
<img width=100% src="images/kineval_welcome.png">

<p>
Your task is to make these objects in starting point mode responsive to keyboard commands.  Specifically, these objects will move upward, stop/start jittering, move closer together, and further apart (although more is encouraged).  To do this, you will modify "kineval/kineval_startingpoint.js" at the sections marked with "STENCIL".  These sections also include code examples meant to be a quick (and very rough) introduction to JavaScript, assuming programming competency in another language. 
</p>

<h3>Brief Code Overview</h3>
<p>
Within the KinEval stencil, the functions my_animate() and my_init() in "home.html" are the principal access points into animation system.  my_animate() is particularly important as it will direct the invocation of functions we develop throughout the AutoRob course.  my_animate() and my_init() are called by the primary process that maintains the animation loop: kineval.animate() and kineval.init() within "kineval/kineval.js".  <b>IMPORTANT</b>: "kineval/kineval.js", kineval.animate(), and kineval.init() should not be modified.  For starting point mode, my_animate() will call startingPlaceholderAnimate() and startingPlaceholderInit().  startingPlaceholderInit() contains JavaScript tutorial-by-example code that initializes variables for this project. startingPlaceholderAnimate() contains keyboard handlers and code to update the positioning of each body of the robot.  By modifying the proper variables at the locations labed "STENCIL", this code will update the transformation matrix for each geometry of the robot (stored in the ".xform" attribute) as a translation in the robot's world.  The ".xform" transform for each robot geometry is then used by kineval.robotDraw() to have the browser render the robot parts in the appropriate locations.
</p>

</p>

<h3>Project Submission</h3>
<p>
To ensure proper submission of your assignments, please do the following:
</p>
 
<p>
<ul>
<li><p>email the course instructor (ocj addrsign umich) with your name, email address, and pointer to your repository,</p> </li>
<li><p>ensure the course instructor knows what repository you are using, and your branch is created and not modified past project deadlines</p></li>
<li><p>ensure the instructor (id:ohseejay) has push/admin access to your repository, which can be confirmed/addressed through email or office hours (or by seeing that the instructor has committed the file "grading.txt")</p></li>
</ul>
</p>

<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-1".  <b>NOTE: spelling matters!</b>  The "Assignment-1" branch is essentially a tag and should not be merged back into the master.  You should continue work from the master branch.
</p>
-->


<h2 id="assignment2">Assignment 2: Pendularm </h2>  
<p>
<b>Due 11:59pm, Friday, October 6, 2017</b>
</p>

<p>
As an introduction to physical dynamics and control, your task is to implement a physical simulator and servo controller for a frictionless <a href="http://en.wikipedia.org/wiki/Pendulum">simple pendulum</a> with a rigid massless rod, and then control this system as a 1 DOF robot with a single motor, a visualization of which is shown below.  
</p>

<p>
<center>
<a href="https://github.com/ohseejay/kineval-stencil/blob/master/pendularm/pendularm1.html"><img width=80% src="images/pendularm.png"></a>
</center>
</p>

<!-- 
<!-- (uncomment marker begin)
-->

<p>
The code stencil for the Pendularm assignment is available within the "pendularm" subdirectory of KinEval in the file <a href="https://github.com/ohseejay/kineval-stencil-fall16/blob/master/pendularm/pendularm1.html">pendularm1.html</a>.
</p>

<p>
For physical simulation, you will implement several numerical integrators for a pendulum with parameters specified in the code stencil.  The numerical integrator will advance the state (angle and velocity) of the pendulum in time given the current acceleration (generated from the pendulum equation of motion).  If implemented successfully, this ideal pendulum should oscillate about the vertical (where the angle is zero) and with an amplitude that preserves the initial height of the pendulum bob.
</p>


<p>
Students enrolled in the undergraduate section will implement numerical integrators for:
</p>

<ul>
<li><p><a href="http://en.wikipedia.org/wiki/Euler%27s_method">Euler's Method</a> </p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Verlet_integration#Velocity_Verlet">Velocity Verlet</a></p></li> 
</ul>



<p>
For motion control, students in both undergraduate and sections will implement a <a href="http://en.wikipedia.org/wiki/PID_controller">proportional-integral-derivative controller</a> to control the system's motor to a desired angle.  This PID controller should output control forces integrated into the system's dynamics.  You will need to tune the gains of the PID controller for stable and timely motion to the desired angle for pendulum with parameters: length=2.0, mass=2.0, gravity=9.81.  
</p>

<p>
For user input, you should be able to: 
</p>

<ul>
<li><p>select the choice of integrator using the [0-4] keys (with the "none" integrator as a default),</p></li> 
<li><p>toggle the invocation of the servo controller with the 'c' or 'x' key (which is off by default),</p></li> 
<li><p>decrement and increment the desired angle of the 1 DOF servoed robot arm use the 'q' and 'e' keys, and</p> </li>
<li><p>momentarily disable the servo controller with 's' key (and allowing the arm to swing uncontrolled).</p></li>
</ul>


<h3> Graduate Section Requirement</h3>

<p>
Students enrolled in the graduate section will implement numerical integrators for:
</p>

<ul>
<li><p><a href="http://en.wikipedia.org/wiki/Euler%27s_method">Euler's Method</a> </p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Verlet_integration#Verlet_integration_.28without_velocities.29">Verlet integration</a></p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Verlet_integration#Velocity_Verlet">Velocity Verlet</a></p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#The_Runge.E2.80.93Kutta_method">Runge-Kutta 4</a></p></li>
</ul>

<p>
to simulate and control both a single pendulum (in "pendulum1.html") a double pendulum (by creating "pendulum2.html").  A code stencil update will be provided for pendularm2.  A working visualization for the double pendularm will look similar to the following:
</p>

<p>
<center>
<a href="https://github.com/ohseejay/kineval-stencil/blob/master/pendularm/pendularm1.html"><img width=80% src="images/pendularm2.png"></a>
</center>
</p>


<h4> Advanced Extensions </h4>

<p>
Of the 4 possible advanced extension points, two additional points for this assignment can be earned by implementing a simulation of a planar <a href="https://en.wikipedia.org/wiki/Inverted_pendulum">cart pole system</a>.  This cart pole implementation should be contained within the file "cartpole.html" under the "project_pendularm" directory.
</p>


<p>
Of the 4 possible advanced extension points, two additional points for this assignment can be earned by implementing a single pendulum simulator in maximal coordinates with a spring constraint enforced by <a href="https://en.wikipedia.org/wiki/Verlet_integration#Constraints">Gauss-Seidel optimization</a>.  This maximal coordinate pendulum implementation should be contained within the file "pendularm1maximal.html" under the "project_pendularm" directory.  An additional point can be earned by extending this implementation to a cloth simulator in the file "cloth_pointmass.html".
</p>


<h3> Project Submission</h3>
<p>
For turning in your assignment, push your updated code to the <b>master</b> branch in your repository.  
</p>

<!-- 
<h3> Additional Notes</h3>
<p>
Students in the graduate section are strongly encouraged to extend their pendularm to a double pendulum.
</p>
(uncomment end) -->

<!--
<hr>
<h1> Material beyond this point has not been assigned.  The descriptions below are unofficial and tentative.</h1>
<hr>
-->

<h2 id="assignment3">Assignment 3: Forward Kinematics</h2>  
<b>Due 11:59pm, Friday, October 20, 2017</b>
<p>
In this assignment, you will render the forward kinematics (FK) of a robot, given its kinematic specification (in the "robots" subdirectory).  To render the robot properly, you will compute matrix coordinate frame transforms for each link and joint of the robot based on the parameters of its hierarchy configuration.  The computation of the matrix transform for each joint and link will allow KinEval's rendering support routines to properly display the full robot.  We will assume the joints will remain in their zero position, saving joint motion for the next assignment.  
</p>

<!-- 
<!-- (uncomment marker begin)
-->

<h3>Just Starting Mode</h3>

<p>
kineval_stencil contains a code template for this assignment as well as all future projects in the course.  This KinEval stencil allows for developing the core of a modeling and control computation stack (forward Kinematics, inverse kinematics, and motion planning) in a modular fashion.  
</p>

<p>
If you open "home.html" in this repository, you should see the jittering disconnected pieces of a robot (described in "robots/mr2.js"), similar to the snapshot below.  This initial mode is the "starting point" state of the stencil to help build familiarity with JavaScript/HTML5 and KinEval.
</p>
<img width=100% src="images/kineval_welcome.png">

<p>
Your task is to make these objects in starting point mode responsive to keyboard commands.  Specifically, these objects will move upward, stop/start jittering, move closer together, and further apart (although more is encouraged).  To do this, you will modify "kineval/kineval_startingpoint.js" at the sections marked with "STENCIL".  These sections also include code examples meant to be a quick (and very rough) introduction to JavaScript, assuming programming competency in another language. 
</p>

<h3>Brief KinEval Stencil Overview</h3>
<p>
Within the KinEval stencil, the functions my_animate() and my_init() in "home.html" are the principal access points into animation system.  my_animate() is particularly important as it will direct the invocation of functions we develop throughout the AutoRob course.  my_animate() and my_init() are called by the primary process that maintains the animation loop: kineval.animate() and kineval.init() within "kineval/kineval.js".  <b>IMPORTANT</b>: "kineval/kineval.js", kineval.animate(), kineval.init(), and any of the given robot descriptions should not be modified.  
</p>

<p>
For starting point mode, my_animate() will call startingPlaceholderAnimate() and startingPlaceholderInit().  startingPlaceholderInit() contains JavaScript tutorial-by-example code that initializes variables for this project. startingPlaceholderAnimate() contains keyboard handlers and code to update the positioning of each body of the robot.  By modifying the proper variables at the locations labed "STENCIL", this code will update the transformation matrix for each geometry of the robot (stored in the ".xform" attribute) as a translation in the robot's world.  The ".xform" transform for each robot geometry is then used by kineval.robotDraw() to have the browser render the robot parts in the appropriate locations.
</p>


<h3>Forward Kinematics</h3>
<p>
Assuming proper completion of Just Starting Mode, you are now ready for implementation of robot forward kinematics.  Ensure the following files are included (within script tags) in your "home.html".  You will modify these files for implementing FK:

<ul>
<li><p>"kineval/kineval_robot_init.js" for initializing your robot object based on a given description object; modification is require to add parent and child references to each link</p></li>
<li><p>"kineval/kineval_forward_kinematics.js" for implementing (a recursive) traversal over joints and links to compute transforms; traversal of forward kinematics is invoked from kineval.robotForwardKinematics() within my_animate() in home.html</p></li>
 <li><p>"kineval/kineval_matrix.js" for the implementation of your vector and matrix routines, such as for matrix multiplication, matrix generation, etc. in kineval_matrix.js</p></li>
</ul>
</p>


<h3> Robot Examples and Initialization</h3>
<p>
Each file in the "robots" subdirectory contains code to create a robot data object .  This data object is initialized the kinematic description of a robot (as well as some meta information and rendering geometries).  The kinematic description defines a hierarchical configuration of the robot's links and joints.  This description is a subset of the <a href="http://wiki.ros.org/urdf">Unified Robot Description Format (URDF)</a> converted into JSON format.  The basic features of URDF are described in <a href="http://wiki.ros.org/urdf/Tutorials/Create%20your%20own%20urdf%20file">this tutorial</a>.  
</p>

<p>
<b>IMPORTANT:</b> The given robot description files should <b>NOT</b> be modified.  Code that requires modified robot description files will fail tests used for grading.  You are welcomed and encouraged to create new robot description files for additional testing.
</p>

<p>
The selection of file with a robot description can occur directly in the URL for  "home.html".  As a default, the "home.html" in the KinEval stencil assumes the "mr2" robot description in "robots/robot_mr2.js".  Another robot description file can be selected directly in the URL by adding a robot parameter.  This parameter is segmented by a question mark and sets the robot file pointer to a given file local location, relative to "home.html".  For example, a URL with "home.html?robot=robots/robot_urdf_example.js" will use the URDF example description.
</p>

<p>
In addition to the given initialization, you should extend the robot object to complete the kinematic hierarchy to specify the parent and children of each link.  This modification should be made in the kineval.initRobotJoints() function in "kineval/kineval_robot_init.js".  The children array of a link should always be defined, which would result in an empty array for leaf nodes in the kinematic tree.
</p>

<p>
<b>Note</b>: KinEval refers to links and joints as strings, not pointers, within the robot object.  robot.joints (as well as robot.links) is an array of data objects that are indexed by strings.  Each of these objects stores relevant fields of information about the joint, such as its transform (".xform"), parent (".parent") and child (".child") in the kinematic hierarchy, local transform information (".origin"), etc.  As such, robot.joints['JointX'] refers to an object for a joint.  In contrast, robot.joints['JointX'].child refers to a string ('LinkX'), that can then be used to reference a link object (as robot.links['LinkX']).   Similarly, robot.links['LinkX'].parent refers to a joint as a string 'JointX' that can then then be used to reference a joint object in the robot.joints array.
</p>

<h3> Invoking Forward Kinematics</h3>

<p>
The function kineval.robotForwardKinematics() in "kineval/kineval_forward_kinematics.js" will be the main point of invocation for your FK implementation.  This function is responsible for updating matrix transforms for the frame of each link and joint with respect to the global world coordinates.  The computed transform for each frame of the robot needs to be stored in the ".xform" field.  For a given link named 'LinkX', this xform field can be accessed as robot.links['LinkX'].xform.  For a given joint named 'JointX', this xform field can be accessed as robot.joints['JointX'].xform.  Once kineval.robotForwardKinematics() completes, the updated transforms for each frame are used by the function kineval.robotDraw() in the support code to render the robot.
</p>


<p>
A matrix stack recursion can be used to compute these global frames, starting from the base of the robot (specified as a string in robot.base).  This recursion should use local translation and rotation parameters of each joint in relation to its parent link in its traversal of the hierarchy.  For a given joint 'JointX', these translation and rotation parameters are stored in the robot object as robot.joints['JointX'].origin.xyz and robot.joints['JointX'].origin.rpy, respectively.  The current global translation and rotation for the base of the robot (robot.base) in the world coordinate frame is stored in robot.origin.xyz and robot.origin.rpy, respectively.
</p>


<p>
To run your FK routine, you must toggle out of starting point mode.  This toggle can be done interactively within the GUI menu or by setting kineval.params.just_starting to false.  The code below in "home.html" controls starting point mode invocation, where single line can be uncommented to use FK mode by default:
</p>

<pre style="color:black"> <code data-language="javascript">
// set to starting point mode is true as default 
//   set to false once starting forward kinematics project
//kineval.params.just_starting = true;

if (kineval.params.just_starting == true) {
    startingPlaceholderAnimate();
    kineval.robotDraw();
    return;
}
</code></pre>

<!--
 (uncomment end) -->

<p>
If implemented properly, the "robots/robot_urdf_example.js" example should produce the following rendering:
</p>
<p> <center>
<img  width=50% src="images/fk_urdf_example.png">
</center> <p>

<p>
The "robots/robot_mr2.js" example should produce the following:
</p>
<p> <center>
<img  width=90% src="images/fk_mr2_example.png">
</center> <p>

<p>
The "robots/robot_crawler.js" example should produce the following:
</p>
<p> <center>
<img  width=90% src="images/fk_crawler_example.png">
</center> <p>


<!--
<!-- (uncomment marker begin)
 -->

<h3> Interactive Hierarchy Traversal</h3>
<p>
Additionally, a correct implementation will be able to interactively traverse the kinematic hierarchically by changing the active joint.  The active joint has focus for user control, which will be used in the next assignment.  For now, we are using the active joint to ensure your kinematic hierarchy is correct.  You should be able to move up and down the kinematic hierarchy with the "k" and "j" keys, respectively.  You can also move between the children of a link using the "h" and "l" keys.
</p>

<h3> Orienting Joint Rendering Cylinders</h3>
<p>
The cylinders used as rendering geometries for joints are not aligned with joint axes by default.  The support code in Kineval will properly orient joint rendering cylinders.  To use this functionality, simply implement a vector cross product function named vector_cross() in your matrix routines.  vector_cross() will be automatically detected and used to properly orient each joint rendering cylinder.
</p>

<h3> Graduate Section Requirement</h3>
<p>
Students in the AutoRob Graduate Section must implement the assignment as described above to work with given examples as well as the Fetch robot description.  Students in the graduate section must also generate a proper Denavit-Hartenberg table for the kinematics of the Fetch robot.    
</p>

<p>
The file "robots/fetch/fetch.urdf/js" contains the robot data object for the Fetch kinematic description.  This JavaScript file converted from the <a href="https://github.com/fetchrobotics/fetch_ros/blob/indigo-devel/fetch_description/robots/fetch.urdf">Fetch URDF description</a> for ROS.  ROS uses a different default coordinate system than threejs, which needs to be taken into account in the FK computation.  Coordinate frames in ROS assumes that the Z, X, and Y axes correspond to the up, forward, and side directions, respectively.  In contrast, threejs coordinate frames assume the Y, Z, and X correspond to the up, forward, and side directions.  The variable robot.links_geom_imported will be set to true when geometries have been imported from ROS and set to false when geometries are defined completely within the robot description file.
</p>

<h4> Advanced Extensions </h4>

<p>
Of the 4 possible advanced extension points, one additional point for this assignment can be earned by creating a new robot description.  This robot description should be placed in the "robots" directory with a filename with your username in the format "robot_uid.js".
</p>

<p>
Of the 4 possible advanced extension points, three additional points for this assignment can be earned by implementing LU decomposition routines for matrix inversion and solving linear systems.  These functions should be named "matrix_inverse" and "linear_solved" and placed within the file containing your matrix routines.
</p>

<h3> Project Submission</h3>
<p>
For turning in your assignment, push your updated code to the <b>master</b> branch in your repository.  
</p>

<!--
(uncomment end HACK)
-->

<p>
A proper implementation for fetch.urdf.js example should produce the following:
</p>
<p> <center>
<img  width=90% src="images/fk_fetch_example.png">
</center> <p>
</p>

<!--
<hr>
<h1> Material beyond this point has not been assigned.  The descriptions below are unofficial and tentative.</h1>
<hr>
-->



<p>

<h2 id="assignment4">Assignment 4: Robot FSM Dance Contest </h2>  
<b>Due 11:59pm, Friday, November 3, 2017</b>
<p>

<p>
For this assignment, you will now enable your robot to execute a dance routine by adding motor rotation to its joints and creating a Finite State Machine (FSM) controller over pose setpoints.  Your FK implementation will be extended to consider angular rotation about each joint axis using quaternions for axis-angle rotation.  The positioning of each joint with respect to a given pose setpoint will be controlled by an simple P servo implementation (based on the Pendularm assignment).  You will implement an FSM controller to update the current pose setpoint based on the robot's current state and predetermined sequence of setpoints.  For a single robot, you will choreograph a dance for the robot by creating an FSM with your design of pose setpoints and an execution sequence. 
</p>

<p>
This controller for the "mr2" was a poor attempt at <a href="https://www.youtube.com/watch?v=roBWj9YPKPo">robot Saturday Night Fever</a> (please do better):
</p>

<a href="asgn4_joint_rotation.png"><img width=100% src="images/asgn4_joint_rotation_small.png"></a>

<p>
This <a href="https://www.youtube.com/embed/WyQ9aoB3bpI">updated dance</a> controller for the Fetch robot is a bit better, but still very far from optimal:
</p>

<center>
<iframe width="420" height="315" src="https://www.youtube.com/embed/WyQ9aoB3bpI" frameborder="0" allowfullscreen></iframe>
</center>


<!-- 
<!-- (uncomment marker begin)
-->

<p>
Assuming proper completion of Assignment 3, ensure the following files are included (within script tags) in your "home.html".  You will modify these files for implementing axis-angle rotation, the pose setpoint controller, and the FSM controller:

<ul>
<li><p>"kineval/kineval_quaternion.js" for your implementation of quaternions for axis-angle rotation in 3D</p></li>
<li><p>"kineval/kineval_forward_kinematics.js" to augment your existing kinematic traversal to account for axis-angle joint rotation</p></li>
<li><p>"kineval/kineval_controls.js" includes function kineval.applyControls() to apply a control update to the robot's base and angle of each joint, as well as updating the camera position; this update just does an addition and does not consider a physical model of dynamics</p></li>
<li><p>"kineval/kineval_servo_control.js" for your implementation of a P servo controller and an FSM pose sequencer</p></li>
</ul>
</p>


<h3>Joint Axis Rotation and Interactive Control</h3>

<p>
Each joint of the robot needs several additional properties for joint rotation and control.  These joint properties for the current angle rotation (".angle"), applied control (".control"), and servo parameters (".servo") have already been created within the function kineval.initRobotJoints().  The joint's angle will be used to calculate a rotation about the joints (normal) axis of rotation vector, specified in the ".axis" field.  The 3D rotation due to joint movement should be accounted for in the robot's forward kinematics and implemented as quaternions in "kineval/kineval_quaternion.js".
</p>

<p>
If joint axis rotation is implemented correctly, you should be able to use the 'u' and 'i' keys to move the currently active joint.  These keys respectively decrement and increment the ".control" field of the active joint.  Through the function kineval.applyControls(), this control value effectively adds an angular displacement to the joint angle.
</p>

<h3>Interactive Base Movement Controls</h3>

<p>
The user interfaces also enables controlling the global position and orientation of the robot base.  In addition to joint updates, the system update function kineval.applyControls() also updates the base state (in robot.origin) with respect to its controls (specified in robot.controls).  With the support function kineval.handleUserInput(), the 'wasd' keys are purposed to move the robot on the ground plane with 'q' and 'e' keys for lateral base movement.  In order for these keys to behave properly, the heading and lateral directions of the robot base are needed such that they respectively express coordinates along local z-axis and x-axis of the base in the global frame.  These vectors need to be computed within your FK implementation and stored within two global variables: robot_heading and robot_lateral.  Each of these variables should be a homogeneous 3D vector stored as a 2D array.
</p>

<p>
If robot_heading and robot_lateral are implemented properly, the robot should now be interactively controllable in the ground plane.
</p>

<h3>Pose Setpoint Controller</h3>

<p>
Once joint axis rotation is implemented, you will implement proportional setpoint controller for the robot joints in function kineval.robotArmControllerSetpoint() within "kineval/kineval_servo_controller.js".  This setpoint controller uses the current angle (".angle"), desired angle, and servo gains (specified in the ".servo" object) of each joint to output a control (".control") for the joint.  The desired angle for a joint 'JointX' is stored in kineval.params.setpoint_target['JointX'] as a scalar. All of these joint object properties are initialized in the function kineval.initRobotJoints() in "kineval/kineval_robot_init.js".
</p>

<p>
For testing, a "clock movement" controller has been provided as the function setpointClockMovement() in "kineval/kineval_setpoint_controller.js".  This function can be invoked by holding down the 'c' key or from the UI.  This controller goes well with <a href="https://www.youtube.com/watch?v=_JPa3BNi6l4"> this song</a>.
</p>

<p>
The robot can servo to the current pose setpoint by holding down the 'o' key or selecting 'persist_pd' from the UI.  Pressing the '0' key sets the current setpoint to the zero pose, where all joint angles are zero.  Stored in kineval.setpoints, up to 9 other arbitrary pose setpoints can be stored by KinEval for pose control.  The current robot pose can be interactively stored by pressing "Shift+number_key" (e.g., "Shift+1").  The current setpoint can be assigned a stored pose by pressing one of the non-zero number keys [1-9].  At any time, the currently stored setpoints can be output to the console as JavaScript code using the JSON.stringify function for the setpoint object, as the statement "JSON.stringify(kineval.setpoints);".  This setpoint array can be included in your code as part of your dance controller.
</p>

<h3>FSM Controller</h3>

<p>
Once your pose setpoint controller is work, a FSM controller should be implemented in the function kineval.setpointDanceSequence() in "kineval/kineval_setpoint_control.js".  The reference implementation uses pose setpoints initialized and stored in kineval.setpoints with a sequence of indices stored in kineval.params.dance_sequence_index and playback index stored in kineval.params.dance_pose_index.  If this convention is not used, the following line in "kineval/kineval_userinput.js" will require modification:
<p>

<pre style="color:black"><code data-language="javascript">
if (kineval.params.update_pd_dance)
    textbar.innerHTML += "executing dance routine, pose " + kineval.params.dance_pose_index + " of " + kineval.params.dance_sequence_index.length;
</code></pre>

<h3> Graduate Section Requirement</h3>
<p>
Students in the graduate section of AutoRob must implement the assignment as described above for the Fetch robot with two additional requirements: 1) proper enforcement of joint types and limits for Fetch robot description, and 2) integration (via <a href="http://wiki.ros.org/rosbridge_suite">rosbridge</a>) of their code with ROS or a <a href="http://docs.fetchrobotics.com/gazebo.html">Gazebo simulation of the Fetch</a>.  

<p>
The Fetch URDF JS file, included in the provided code stencil, contains joints with with various types that correspond to different types of motion:
</p>

<p>
<ul>
<li><p>continuous: rotation about the joint axis with no joint limits</p></li>
<li><p>revolute: rotation about the joint axis with joint limits</p></li>
<li><p>prismatic: translation along the joint axis with joint limits</p></li>
<li><p>fixed: no motion of the joint</p></li>
</ul>
</p>

<p>
Joints are considered to be continuous as the default.  Joints with undefined motion types must be treated as continuous joints.
</p>

<p>
Your code can interface with any robot (or simulated robot) running rosbridge/ROS using the function kineval.rosbridge() in "kineval/kineval_rosbridge.js".  This code requires that the rosbridge_server package is running in a ROS run-time environment and listening on a websocket port, such as for ws://fetch7:9090.  If your FK implementation is working properly, the model of your robot in the browser will update along with the motion of the robot based on the topic subscription and callback.  This functionality works seamlessly between real and simulated robots.  To control the robot, a rosbridge publisher must be written to update the ROS topic "/arm_controller/follow_joint_trajectory/goal" with a message of type "control_msgs/FollowJointTrajectoryActionGoal".
</p>

<p>
Machines running rosbridge, ROS, and Gazebo for the Fetch will be available during special sessions of the class.  Students are encouraged to install and run the Fetch simulator on their own machines based on <a href="http://docs.fetchrobotics.com/gazebo.html">this tutorial</a>.
</p>

<h4> Advanced Extensions </h4>

<p>
Of the 4 possible advanced extension points, one additional point for this assignment can be earned by adding the capability of displaying laser scans from a real or simulated Fetch robot.
</p>

<p>
Of the 4 possible advanced extension points, four additional points for this assignment can be earned by adding the capability of displaying 3D point clouds from a real or simulated Fetch robot and computing surface normals about each point.
</p>

<p>
Of the 4 possible advanced extension points, four additional points for this assignment can be earned by implementing dynamical simulation through the recursive <a href="http://robotics.usc.edu/~aatrash/cs545/CS545_lecture_11_new.pdf">Newton-Euler algorithm</a> (Spong Ch.7).  This dynamical simulation update be implemented as function kineval.updateDynamicsNewtonEuler() in the file "kineval/kineval_controls.js".  In "home.html", the call to kineval.updateDynamicsNewtonEuler() should replace the call purely kinematic update in kineval.applyControls().
</p>


<h3> Project Submission</h3>
<p>
For turning in your assignment, push your updated code to the <b>master</b> branch in your repository.  
</p>


<p>

<hr>
<h1> Material beyond this point has not been assigned.  The descriptions below are unofficial and tentative.</h1>
<hr>
<!--
-->


<!-- 
(uncomment end) -->


<p>



<h2 id="assignment5">Assignment 5: Inverse Kinematics </h2>  
<p>
<b>Due 11:59pm, Wednesday, November 15, 2017</b>
<p>

For this assignment, you will now control your robot to reach to a given point in space through inverse kinematics for position control of the robot endeffector.  Inverse kinematics will be implemented through gradient descent optimization with both the Jacobian Transpose and Jacobian Pseudoinverse methods, although only one will be invoked at run-time.  
<p>

<img width=100% src="images/kineval_fetch.png">

As shown in the video below, if successful, your robot will be able to continually place its endeffector (indicated by the blue cube) exactly on the reachable target location (indicated by the green cube), regardless of the robot's specific configuration:

<center>
<iframe width="420" height="315" src="https://www.youtube.com/embed/ag0j8HzFRzc" frameborder="0" allowfullscreen></iframe>
</center>


<!--
<img src="images/kineval_snapshot_2.png" width=100%>
-->


<!-- -->
<!-- (uncomment marker begin)

<p>
The core of this assignment is to complete the kineval.iterateIK() function in the file kineval/kineval_inverse_kinematics.js.  This function is invoked within the function kineval.inverseKinematics()  with three arguments: 
</p>

<ul>
<li><p>endeffector_target_world: an object with two fields with the target endeffector position (as a 3D homogeneous vector) and orientation (as Euler angles) in the world frame</p></li>
<li><p>endeffector_joint: the name of the joint directly connected to the endeffector</p></li>
<li><p>endeffector_position_local: the location of the endeffector in the local joint frame</p></li>
</ul>

<p>
From these arguments and the current robot configuration, the kineval.iterateIK() function will compute controls for each joint.  Upon update of the joints, these controls will move the configuration and endeffector of the robot closer to the target.
</p>

<p>
kineval.iterateIK() should also respect global parameters for using the Jacobian pseudoinverse (through boolean parameter kineval.params.ik_pseudoinverse) and step length of the IK iteration (through real-valued parameter kineval.params.ik_steplength).  Kineval also maintains the current endeffector target information in the kineval.params.ik_target parameter.
</p>


<p>
IK iterations can be invoked through the user interface by holding down the 'p' key.  Further, the 'r'/'f' keys will move the target location up/down.  When performing IK iterations, the endeffector and its target pose will be rendered as cube geometries in blue and green, respectively.  
</p>

<p>
In implementing this IK routine, please remember the following:
<p>
<ul>
<li><p>Computation of the Jacobian need only to occur with respect to the joints along the chain from the endeffector joint to the robot base</p></li>
<li><p>The location of the endeffector needs to be computed using transforms resulting from the robot's forward kinematics </p> </li>
<li><p>Matrix inversion can be invoked by using the provided routine numeric.inv(mat), available through <a href="http://www.numericjs.com/">numericjs</a> </p></li>
<li><p>The computed velocity in configuration space should be applied to the robot through the joint.controls field of each joint </p></li>
</ul>

<p>
Students enrolled in EECS 398-002 will implement inverse kinematics for only the position of the endeffector.
</p>

<h3> IK Random Trial </h3>

<p>
All students in the AutoRob course are expected to run their IK controller with the random trial feature in the KinEval stencil.  The IK random trial is executed through the function kineval.randomizeIKtrial() in the file "kineval/kineval_inverse_kinematics.js".  This function is incomplete in the provided stencil.  Code for this function to properly run the random trial will be made available upon request through the course discussion channel.
<p>

<h3> Graduate Section Requirement</h3>

<p>
Students enrolled in the graduate section of AutoRob will implement inverse kinematics for both the position and orientation of the endeffector, especially for the Fetch robot.  The default IK behavior will be for endeffector position control.  Both endeffector position and orientation are controlled when the boolean parameter kineval.params.ik_orientation_included is set to true.  
</p>

<h4> Advanced Extensions </h4>

<p>
Of the 4 possible advanced extension points, one additional point for this assignment can be earned by reaching to 100 targets in a random trial within 60 seconds.  A video of this execution must be provided to demonstrate this achievement.
</p>

<p>
Of the 4 possible advanced extension points, four additional points for this assignment can be earned by implementing the <a href="http://ieeexplore.ieee.org/document/86079/">Cyclic Coordinate Descent (CCD)</a> inverse kinematics algorithm by Wang and Chen (1991).  This function should be implemented in the file "kineval/kineval_inverse_kinematics.js" as another option within the function kineval.iterateIK().
</p>

<p>
Of the 4 possible advanced extension points, three additional points for this assignment can be earned by extending your IK controller to use a potential field to avoid collisions.
</p>



<h3> Project Submission</h3>

<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-5".  
<p>

(comment end) -->
<!-- -->

<!--
<hr>
<h1> Material beyond this point has not been assigned.  The descriptions below are unofficial and tentative.</h1>
<hr>
-->



<h2 id="assignment6">Assignment 6: Motion Planning  </h2>  
<p>
<b>Due 11:59pm, Wednesday, December 6, 2017</b>
</p>


<p>
For this assignment, you will now implement a collision-free motion planner to enable your robot to navigate from a random configuration in the world to its home configuration (or "zero configuration").  This home configuration is where every robot DOF has a zero value.  For planning, configuration space includes the state of each joint and the global orientation and position of the robot base.  Thus, the robot must move to its original state at the origin of the world.  Motion planning will be implemented through the <a href="https://personalrobotics.ri.cmu.edu/files/courses/papers/Kuffner00-rrtconnect.pdf">RRT-Connect algorithm</a> (described by Kuffner and LaValle).  
</p>


<p>
The graduate section will additionally implement the <a href="http://dspace.mit.edu/openaccess-disseminate/1721.1/63170">RRT-Star</a> motion planner of Karaman et al. (ICRA 2011).

</p>

<img src="images/asgn6_motionplan.png"  width=100%>
<p>

<!-- -->
<!-- (uncomment marker begin)

<p>
The core of this assignment is to complete the robot_rrt_planner_init() and robot_rrt_planner_iterate() in the provided kineval_rrt_connect.js stencil.  For successful execution, your implementation of RRT-Connect, the provided collision detection system, and a single specification of world geometry has been included in home.html:
</p>

<pre style="color:black"><code data-language="javascript">
&lt script src="kineval_rrt_connect.js" >&lt/script> 
&lt script src="kineval_collision.js" >&lt/script> 
&lt script src="worlds/world_basic.js" >&lt/script>
</code></pre>

<p>
The code stencil will automatically load a default world.  A world can also be specified as an appended parameter within the URL, in the form of "?world=worlds/world_name.js".
The result of including a world file are the global objects "robot_boundary" descrbing the min and max values of the world boundaries along the X, Y, and Z axes and "robot_obstacles" as the locations and radii of sphere obstacles.  To ensure these worlds rendered in the display and available for collision detection, the geometries of the world are included through the provided call to kineval.initWorldPlanningScene() in kineval/kineval.js.
<p>

Note: your planner should be constrained such that the search does not consider configurations where the base is outside the X-Z plane.  Specifically, the base should not translate along the Y axis, and should not rotate about the X and Z axes.

<h3>First step: add collision detection</h3> 
<p>
Your RRT-Connect implementation will depend on detection of collisions (provided by the function kineval.isCollision() in kineval_collision.js) with respect to a specified world geometry.  Worlds are specified as a rectangular boundary and sphere obstacles.  A collection of worlds are provided in the "worlds/" subdirectory of kineval_stencil.  The collision detection system performs two forms of tests: 1) testing of the base position of the robot against the rectangular extents of the world, which is provided by default, and 2) testing of link geometries for a robot configuration against spherical objects, which depends on code you will write.  

Collision testing for links in a configuration is performed by AABB/Sphere tests that require the bounding box of each link's geometry in the coordinates of that link.  This bounding box is computed by the following within the loop inside kineval.initRobotLinksGeoms() in kineval.js:

<pre style="color:black"><code data-language="javascript">
  // bounding box of robot link in local link coordinates
  robot.links[x].bbox = new THREE.Box3;
  robot.links[x].bbox = 
    robot.links[x].bbox.setFromObject(robot.links[x].geom);
</code></pre>

(end comment) --> 
<!-- -->

<p>
Even before your planner is implemented, you can use the collision system interactively with your robot.  The provided kineval.isCollision() function will test the current configuration of the robot.  When the robot is detected to be in collision, one of the colliding links will be highlighted with a red wireframe.  There could be many links in collision, but only one will be highlighted.  

<p>
<center>
<img src="images/rrt_collision_boundary.png" width=48%>
<img src="images/rrt_collision_link.png" width=48%>
</center>
<p>

<!-- -->
<!-- (uncomment marker begin)

The call to kineval.isCollision() has been placed within my_animate() in home.html:

<pre style="color:black"><code data-language="javascript">
    // show if robot is currently in collision
    kineval.isCollision();
</code></pre>


<h3>Updating kineval_collision for your implementation</h3>
<p>

To complete the collision system, you will need to modify the forward kinematics calls in kineval/kineval_collision.js.  Specifically, you will need to perform a traversal of the forward kinematics of the robot for an arbitrary robot configuration within the function kineval.poseIsCollision().  kineval.poseIsCollision() takes in a vector in the robot's configuration space and returns either a boolean false for no detected collision or a string with the name of a link that is in collision.  As a default, this function performs base collision detection against the extents of the world.  For collision detection of each link, this function will make a call to function that you create called robot_collision_forward_kinematics() to recursively test for collisions along each link.  Your collision FK recursion should use the link collision function, collision_FK_link(), provided below along with a joint traversal function properly positions the link and joint frames for the given configuration.
</p>


<pre style="color:black"><code data-language="javascript">
function collision_FK_link(link,mstack,q) {

  // this function is part of an FK recursion to test each link 
  //   for collisions, along with a joint traversal function for
  //   the input robot configuration q
  //
  // this function returns the name of a robot link in collision
  //   or false if all its kinematic descendants are not in collision

  // test collision by transforming obstacles in world to link space
  mstack_inv = numeric.inv(mstack);
  // (alternatively) mstack_inv = matrix_invert_affine(mstack);

  var i; var j;

  // test each obstacle against link bbox geometry 
  //   by transforming obstacle into link frame and 
  //   testing against axis aligned bounding box
  for (j in robot_obstacles) {

    var obstacle_local = 
      matrix_multiply(mstack_inv,robot_obstacles[j].location);

    // assume link is in collision as default
    var in_collision = true;

    // return false if no collision is detected such that
    //   obstacle lies outside the link extents 
    //   along any dimension of its bounding box
    if (
      (obstacle_local[0][0]<
       (link.bbox.min.x-robot_obstacles[j].radius)
      )
      ||
      (obstacle_local[0][0]>
       (link.bbox.max.x+robot_obstacles[j].radius)
      )
    )
      in_collision = false;

    if (
      (obstacle_local[1][0]<
       (link.bbox.min.y-robot_obstacles[j].radius)
      )
      ||
      (obstacle_local[1][0]>
       (link.bbox.max.y+robot_obstacles[j].radius)
      )
    )
      in_collision = false;

    if (
      (obstacle_local[2][0]<
       (link.bbox.min.z-robot_obstacles[j].radius)
      )
      ||
      (obstacle_local[2][0]>
       (link.bbox.max.z+robot_obstacles[j].radius)
      )
    )
      in_collision = false;

    // return name of link for detected collision if
    //   obstacle lies within the link extents 
    //   along all dimensions of its bounding box
    if (in_collision)
      return link.name;
  }

  // recurse child joints for collisions, 
  //   returning name of descendant link in collision
  //   or false if all descendants are not in collision
  if (typeof link.children !== 'undefined') { 
    var local_collision;
    for (i in link.children) {
       // STUDENT: create this joint FK traversal function 
       local_collision = 
         collision_FK_joint(robot.joints[link.children[i]],mstack,q)
       if (local_collision)
         return local_collision;
     }
  }

  // return false, when no collision detected for this link and children
  return false;
}
</code></pre>


kineval_collision.js uses matrix and quaternion calls based on the reference implementation (i.e., my code).  Your matrix and quaternion calls likely have a different structure to the function arguments and returned data structures.  You should either:

 <ul> 
  <li><p>modify calls to matrix/quaternion routines to fit your functions, or</p></li>

  <li><p> use a modified version of your own FK with the collision test added to the link traversal function (remember: you need the inverse of the matrix stack for collision testing in a link frame)</p></li>
</ul>
<p>

<p>
You can feel free to implement matrix_invert_affine() instead of using numeric.inv().  Affine transforms can be inverted (in constant time, Quiz 2!) through a much simpler process than the generic matrix inversion, which is O(n^3) for Gaussian elimination. 
</p>
<p>
If successful to this point, you should be able to see the collision world of the robot, move around this world, and see the colliding link display a red wireframe when a collision occurs.
<p>


<h3>Implementing and invoking the planner</h3> 

<p>
Your motion planner will be implemented in the file kineval/kineval_rrt_connect.js through the functions kineval.robotRRTPlannerInit() and robot_rrt_planner_iterate().  The kineval.robotRRTPlannerInit() function should be modified to initialize the RRT trees and other necessary variables. The robot_rrt_planner_iterate() function should be modified to perform a <b>single</b> RRT-Connect iteration based on the current RRT trees.  Basic RRT tree support functions are provided for initialization, adding configuration vertices (which renders "breadcrumb" indicators of base positions explored), and adding graph edges between configuration vertices.  This function should <b>not</b> use a for loop to perform multiple planning iterations, as this will cause the browser to block and become unresponsive.  Instead, the planner will be continually called asynchronously by the code stencil until a motion plan solution is found.
</p>

<p>
Once implemented, your planner will be invoked interactively by first moving the robot to an arbitrary non-colliding configuration in the world and then pressing the "m" key.  The "m" key will request the generation of a motion plan.  While the planner is working, it will not accept new planning requests.  Thus, you can move the robot around while the planner is executing.
</p>


<h3>Planner output</h3> 
<p>
The output of your planner will be a motion path in a sequentially ordered array (named kineval.motion_plan[]) of RRT vertices.  Each element of this array contains a reference to an RRT vertex with a robot configuration (.vertex), an array of edges (.edges), and a threejs indicator geometry (.geom).  Once a viable motion plan is found, this path can be highlighted by changing the color of the RRT vertex "breadcrumb" geom indicators.  The color of any configuration breadcrumb indicator in a tree can be modified, such as in the following example for red:
</p>

<pre style="color:black"><code data-language="javascript">
  tree.vertices[i].geom.material.color = {r:1,g:0,b:0};
</code></pre>

<p>
The user should should be able to interactively move the robot through the found plan.  After adding the following code below to user_input() in kineval_userinput.js, the "n" and "b" keys to move the robot to the next and previous configuration in the found path, respectively.  These user key presses will respectively increment and decrement the parameter kineval.motion_plan_traversal_index such that the robot's current configuration will become:
</p>

<pre style="color:black"><code data-language="javascript">
  kineval.motion_plan[kineval.motion_plan_traversal_index]
</code></pre>

<p>
Note: we are <b>NOT</b> using robot.controls to execute the found path of the robot.  Although this can be done, the collision system does not currently test for configurations that occur due to the motion between configurations.
</p>

<h3>Testing</h3>

<p>
<img src="images/asgn6_scurve_small.png" width=100%>

<p>
Make sure to test all provided robot descriptions from a reasonable set of initial configurations within all of the provided worlds, ensuring that:
</p>

<p>
<ul>
<li> <p>a valid non-colliding path is found and can be traversed,</p></li>
<li> <p>the robot does not to take steps longer than 1 unit,</p></li>
<li> <p>the robot base does not move outside the X-Z plane.  Specifically, the base should not translate along the Y axis, and should not rotate about the X and Z axes.</p></li>
</ul>
</p>

<h3> Graduate Section Requirement</h3>

<p>
In addition to the requirements above, students in the graduate section must also implement the <a href="http://dspace.mit.edu/openaccess-disseminate/1721.1/63170">RRT-Star</a> motion planning algorithm and test to ensure:
</p>

<p>
<ul>
<li> <p>joint limits for the different joint types are respected, and </p></li>
<li> <p>the "fetch" robot should be able to navigate all of the provided worlds.</p></li> 
</ul>
</p>


<h4> Advanced Extension </h4>

<p>
Of the 4 possible advanced extension points, one additional point for this assignment can be earned by adding the capability of motion planning to an arbitrary robot configuration. 
</p>
<p>
Of the 4 possible advanced extension points, two additional points for this assignment can be earned by using the A-star algorithm for base path planning in combination with RRT-Connect for arm motion planning. 
</p>
<p>
Of the 4 possible advanced extension points, four additional points for this assignment can be earned by implementation of triangle-triangle tests for collision detection between robot and planning scene meshes. 
</p>


<h3>Warning: Respect configuration space</h3> 

<p>
The planner should produce a collision-free path in configuration space (over all robot DOFs) and not just the movement of the base on the ground plane.  If your planner does not work in configuration space, it is sure to fail tests used for grading.
</p>

<h3>Highly recommended: start with HTML5 Canvas Stencil </h3>

<img width=100% src="images/asgn6_rrt_canvas_stencil_small.png">

<p>
Using the browser for as a development environment has many benefits.  However, when coding mistakes occur, it will make the browser lock up and be completely unusable.  Such mistakes can be especially difficult to debug when the overhead of rendering with threejs is involved.  
</p>

<p>
To help you get started, the path planning code stencil in the "search_canvas" directory has entry points for developing your core RRT routines.  This stencil will allow you to implement the RRT-Connect algorithm in simplified 2D worlds with provided routines for visualization and collision.  Because the RRT is invariant across configuration spaces, an RRT developed for the 2D Canvas world should easily port to the N-D threejs world, with minor changes for invoking drawing routines.
</p>

<p>

<p>
For turning in your assignment, create a branch in your repository labeled "Assignment-6".  
<p>

(comment end) -->
<!-- -->

<h2 id="assignment7">Assignment 7: The best use of robotics? </h2>  
<p>
<b>Slides due 11:59pm, Friday, December 8, 2017</b>
<b>Presentation due 1:30pm, Monday, December 11, 2017</b>
<p>

Scenario: An investor is considering giving you 3 million dollars (cold hard USD cash, figuratively).  This investor has been impressed by your work with KinEval and other accomplishments while at the University of Michigan.  They are convinced you have the technical ability to make a compelling robot technology... but, they are unsure how this technology could produce something useful.  Your task is to make a convincing pitch for a  robotics project that would yield a high return on investment, as measured by some metric (financial profit, good for society, creating of new knowledge, etc.). 

<!-- -->
<!-- (uncomment marker begin)
<p>
You will get 2 minutes to make a pitch to develop something useful with robots.  Consider the instructor and your classmates as the people that need to be convinced.  As a guideline, your pitch should address an opportunity (presented by a need or a problem), your planned result (as a system, technology, product, and/or service), and how you will measure successful return on investment.  Return on investment can be viewed as financial profit (wrt. venture capital), good for society (wrt. a government program), creation of new knowledge or capabilities (wrt. a grant for scientific research).  Remember, the purpose is to convince and inspire about what is possible, rather than dive into specifics.
<p>
The last scheduled class period and a little more (Monday December 12th, 1:30-4:30pm) will be dedicated to student presentations to pitch ideas on the best use of robotics.  
</p>

<p>
Please post your slides to the "asgn7-best-use" discussion channel before 11:59pm on Friday December 9th.  Your slides must include the title of your presentation, your name, and your UID.  Slides will only be accepted in PDF format, although embedding of videos or links to videos will be accepted.  You can post new versions of your slides up to the submission deadline on December 9th.
</p>
(end comment) -->
<!-- -->
<p>
The pitch judged to be the most convincing will get first dibs.
</p>

<!--
<hr>
<h1> Assignments beyond this point have not been assigned.  The descriptions below are unofficial and tentative.</h1>
<hr>
-->

<p>
<br>
<br>
<h1>Additional Materials</h1>

<h2 id="git_tutorial">Appendix: Git-ing Started with Git</h2>  

<p>
Using version control effectively is an essential skill for both the AutoRob course and, more generally, contributing to advanced projects in robotics research and development.  git is arguably the most widely used version control system at current.  Examples of the many robotics projects using git include: 
<a href="https://github.com/lcm-proj">Lightweight Communications and Marshalling</a>,
<a href="https://github.com/ros">the Robot Operating System</a>,
<a href="https://github.com/RobotWebTools">Robot Web Tools</a>,
<a href="https://github.com/fetchrobotics">Fetch Robotics</a>,
<a href="https://bitbucket.org/nasa_ros_pkg/nasa_r2_simulator">the NASA Robonaut 2</a>, and
<a href="https://github.com/RethinkRobotics">the Rethink Baxter</a>.
To help you use git effectively, the course staff has added the tutorials below for getting started with git.
This is meant to be a starting guide to using git, bash, and Git Bash.  For a more complete list of commands and features of git, you can refer to the following guides: <a href="http://git-scm.com/book/en/v2/Getting-Started-Installing-Git">The Git Pro book</a> or The <a href="http://www.mathworks.com/help/instrument/using-tcpip-server-sockets.html">Basic git command line reference for windows users</a>. An interactive tutorial for git is available at <a href="http://learngitbranching.js.org/">LearnGitBranching</a>.
</p>



<h3>Installing git</h3>

<p>
The AutoRob course assumes git is used from an command line terminal to work with a git hosting service, such as <a href="github.com">GitHub</a> or <a href="bitbucket.com">Bitbucket</a>.  Such terminal environments are readily available in Linux and Mac OSX through their respective terminal programs.  For MS Windows, we are recommending <a href="https://openhatch.org/missions/windows-setup/install-git-bash">Git Bash</a>, although several other viable alternatives exist.  Applications that provide a Graphical User Interface for git are not recommended.  
</p>

<p>
git can be installed on Linux through a common package managment system, based on your distribution, with one of the following commands:
</p>

<pre style="color:black"><code data-language="javascript">
sudo yum install git-all
</code></pre>
<pre style="color:black"><code data-language="javascript">
sudo apt-get install git-all
</code></pre>

<p>
For Mac OSX, git can be installed on its own using the <a href="https://code.google.com/p/git-osx-installer/">Git-OSX-Installer</a> or as part of larger set of <a href="https://en.wikipedia.org/wiki/Xcode">Xcode</a> build tools. 
For MS Windows, we are recommending <a href="https://openhatch.org/missions/windows-setup/install-git-bash">Git Bash</a>, although several other viable alternatives exist.  
</p>

<p>
If you have a command line terminal running, you should see a shell environment that looks something like this (screenshot from Git Bash):
</p>

<center>
<img width=80% src="images/gitbash.png">
</center>

<p>
If you have git installed, you should should be able to enter the "git" command and see the following usage information printed (screenshot from OSX):
</p>

<center>
<img width=80% src="images/git_terminal_osx.png">
</center>

<h3>Cloning your repository</h3>

<p>
The most common thing that you will need to do is pull and push files from and to your git hosting service. Upon opening Git Bash, you will need to go to the location of <b>both</b> your GitHub/Bitbucket repository on the web and your git workspace on your local computer.  Our first main step is to clone your remote repository onto your local computer.  Towards this end, the next step is to open your terminal application and determine your current directory, assuming you will use this directory to create a workspace.  For Linux and OSX, the terminal should start in your home directory, often "/home/username" or "/Users/username".  For Git Bash on Windows, the default home directory location could be the Documents in your user directory, or the general user folder within "C:\Users". 
</p>

<p>
From your current directory, you can use Bash commands to view and modify the contents of directories and files.  You can see a list of the files and folders that can be accessed using ls (list) and change the folder using the command cd (change directory) as shown below. If you believe that the directory has files in addition to folders, but would like a list of just the folders, then the command ls –d */ can be used instead of ls.  Below is a quick summary of relevant Bash commands:
</p>

<p>
<ul>
<li>"ls" prints a listing of files in the current directory
<li>"pwd" prints the location of the current directory in the filesystem
<li>"cd [NameFolder]" moves the terminal to a new directory in the filesystem
<li>"ls [Expression]" prints a listing of files in the current directory matching the given Expression; ls r* prints all files starting with the character 'r'
<li>"mkdir [NameFolder]" creates a folder within the current directory. If the folder name has spaces, then NameFolder will need to be in double quotes.
<li>"rmdir [NameFolder]" removes a specified empty folder. If it is not empty, the folder will not be removed.
<li>"rm –rf [NameFolder]" removes a specified folder and all the contents
<li>"touch [FileName]" creates a single empty text file
<li>"touch [FIleName1.txt] [FileName2.txt]..." creates multiple empty text files
<li>"rm [FileName]" removes a specific file from the current directory
<li>"rm –i <FileName]" confirmation prompt required before removing file from current directory. The file name cannot have spaces.
<li>"rm –v [FileName]" removes the file and reports in console
</ul>
</p>

<p>
You are now ready to clone a copy of your remote repository and populate it with files for AutoRob projects.  It assumed that you have already created a repository on your git hosting service, given the course staff access to this repository, and provided a link of your repository to the course staff.  This repository link (in the form of "https://github.com/user_name/repository_name.git") will now be used to clone a copy of your remote repository onto your local machine using the following git command below.  This command will clone the repository contents to a subdirectory labeled with the name of the repository:
</p>

<pre style="color:black"><code data-language="javascript">
  git clone [repository URL link]
</code></pre>

<p>
This directory should be listed and inspected to ensure it has been cloned with the contents of the repository, matching the remote repository from your git hosting service.  If this is a new repository, it is not problem for this directory to be empty:
</p>

<pre style="color:black"><code data-language="javascript">
  ls [repository_name]
</code></pre>

<p>
You can also check for differences between the files on your computer and the remote repository using git status as shown below.  If you receive the message shown in the example below, then there are no differences. If there are differences, then it will have the number of files which are different highlighted in red. 
</p>

<pre style="color:black"><code data-language="javascript">
$ git status
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working directory clean
</code></pre>

<h3>Important: workspace is not the same as repository</h3>

<p>
You should now have a local copy of your repository with a workspace in a subdirectory.  It is critical to note that your local repository is different than the subdirectory with your current workspace.  Your workspace is not automatically tracked by the version control system and considered ephemeral.  Any changes made to your workspace must be committed back into the local repository to be recognized by the version control system.  Further, any changes committed to your local repository must also be pushed remotely to be recognized by your git hosting service.  Thus, any changes made to your workspace can be lost if not committed and pushed, which will be discussed more in later sections.
</p>

<h3>Populating your repository with project stencil code</h3>

<p>
In a separate directory, clone the kineval-stencil-fall16 repository to a subdirectory on your local machine:
</p>

<pre style="color:black"><code data-language="javascript">
  cd [home_directory]
  git clone https://github.com/ohseejay/kineval-stencil-fall16.git
</code></pre>

<p>
Inspect this directory to ensure it has been cloned with the contents of the repository:
</p>

<pre style="color:black"><code data-language="javascript">
  cd kineval-stencil-fall16
  ls
</code></pre>

<p>
and open "home.html" from this directory in a web browser and ensure you see the starting point picture below:
<!--
for <a href="#assignment1">Assignment 1</a>.  
-->
</p>

<img width=100% src="images/kineval_welcome.png">

<p>
Then, copy the kineval-stencil-fall16 files to the directory with your workspace
</p>

<pre style="color:black"><code data-language="javascript">
  cd [home directory]
  cp -r kineval-stencil-fall16/* <repository_name>/
</code></pre>

<p>
As these copied files are new to your working repository, they need to be added to the repository to ensure they are tracked for version control.  These files are added with the following commands:
</p>

<pre style="color:black"><code data-language="javascript">
  cd [repository name]
  git add * 
</code></pre>

<p>
Below is a more detailed summary of git commands for adding files from your workspace to your repository:
</p>

<ul>
<li>"git add" adds changed files to the next commit. There are several different options which can follow this command. 
<li>"git add –A: adds all new files and changes to the next commit including deletions
<li>"git add ." adds all new files and changes to the next commit without deletions
<li>"git add –u" adds all changes to the next commit without new files
</ul>

<h3>Commit and push to update your repository</h3>

<p>
Whenever you make any significant changes to your repository, these changes should be committed to your local repository and pushed to your remote repository.  Such changes can involve adding new files or modifying existing files in your local workspace.  For such changes, you will first commit changes from your workspace to your local repository using the git commit command:
</p>

<pre style="color:black"><code data-language="javascript">
git commit -a -m "message describing changes"
</code></pre>

<p>
and then pushing these changes from your local repository to a synced repository on your git hosting service:
</p>

<pre style="color:black"><code data-language="javascript">
git push
</code></pre>

<p>
This commit will occur to the "master" branch of your repository.
</p>

<p>
Note: the change files must be located in the correct repository folder on your local computer and these commands should be performed in the local workspace directory.  Below is a more detailed summary of git commands for adding files from your workspace to your repository:
</p>

<ul>
<li>"git commit" commits files with changes. There are several options that can follow this. The message text is required and is good practice to list changes that you have made. GitHub is good at tracking changes.
<li>"git commit [FileName] -m 'Message'" commits changes to a specific file
<li>"git commit –a “Message'" commits all files changed since last commit
<li>"git commit –a –m “Message'" commits all files changed since last commit but not new files
<li>"git push" pushes the committed changes to remote repository 
</ul>

<p>
Once you have committed and pushed, your local workspace becomes redundant as your changes have been stored and tracked remotely.  The local workspace can now be deleted without concern.  This local workspace can also be updated with changes to the remote repository by pulling.
</p>

<h3>Pulling remote changes</h3>

<p>
Changes be made to your remote repository, potentially by other collaborators, without being tracked by your local repository.  This can lead to potential versioning conflicts when committed changes contradict each other.  For the AutoRob course, versioning conflicts should not be a problem because commits to your repository should be yours alone.  That said, one good practice is to ensure your workspace, local repository, and remote repository are synced before making any changes.  A brute force method for doing this is to re-clone your repository each time you begin to make changes.  Another option is to pull remote changes into your local repository and workspace using the git pull command (or git fetch command):
</p>

<pre style="color:black"><code data-language="javascript">
cd [repository_name]
git pull
</code></pre>

<p>
Below is a more detailed summary of git commands for pulling and fetching:
</p>

<ul>
<li>"git pull [RemoteName]" is used for retrieving commits and merging the files to what is already on the computer. This may make changes to the files that are already there; effectively, this is a fetch followed by a merge.  If you need to pull directly from the repository which already exists and has been accessed through the change directory command, then you do not list a [RemoteName]. 
<li>"git fetch <RemoteName>" used for retrieving commits from a repository that does not already exist on the user’s computer. This creates an exact copy of the files to your local repository and not to the workspace. 
</ul>

<!--
Some easy options for controlling previous and current versions of files can be done through the following commands.
git reset -- hard undo everything from last commit
git reset – hard ORIG_HEAD undo last successful merge and following changes
git reset –soft HEAD^ undo most recent commit
git reset HEAD [FileName] remove a file from the next commit
-->

<h3>Branching</h3>

<p>
Branching is an effective mechanism for work in a repository to be done in parallel with changes merged at a later point.  A branch essentially creates a copy of your work at a particular version.  Branches are independently tracked by the version controller and can be merged together when requested (which collaboratively results in a "pull request").  The larger story for branching and merging is outside the scope of AutoRob.
</p>

<p>
The working version of your code, which you submit for grading, is expected to be in the "<i>master</i>" branch of your repository.  When working on a new assignment, it is recommend that you create a branch for this new work.  This allows your stable code in the master branch to be undisturbed while you continue to modify your code.  Once your work for this assignment is done, you can then update your <i>master</i> by merging in your assignment branch.  Stylistically, it is helpful to use the name <i>Assignment-X</i> for your assignment branch for Project number <i>X</i>.
</p>

<p>
The simplest means for branching in this context is to use the branching feature from the webpage of your remote repository.  From GitHub, simply select the master branch from the "Branch: " button and enter the name of the branch to be created.  From Bitbucket, select the "Branches" icon from the left hand toolbar and follow the instructions for branch creation.  If successful, you should see a list of branches that can each be inspected for their respective contents.  Branches can also be deleted from this interface.
</p>

<p>
A branch can also be created from the command line by the following, which will create a copy of the current branch:
</p>

<pre style="color:black"><code data-language="javascript">
git branch [branch_name]
</code></pre>

<p>
You can switch between branches with the following command:
</p>

<pre style="color:black"><code data-language="javascript">
git checkout [branch_name]
</code></pre>

<p>
as well as clone a specific branch from a repository:
</p>

<pre style="color:black"><code data-language="javascript">
git clone -b [branch_name] [repository URL link]
</code></pre>

<p>
Good luck and happy hacking!
</p>

<br>
<br>

<img width=100% src="images/um_fetch.jpg">


        <!-- TYPEKIT -->
        <script type="text/javascript" src="resources/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script type="text/javascript" src="resources/rainbow_github.min.js"></script>
        <script type="text/javascript" src="resources/rainbow_github_generic.js"></script>
<!--
        <script type="text/javascript" src="//use.typekit.net/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/rainbow.min.js"></script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/language/generic.js"></script>
-->

</body>

</html>
